{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "character_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmgy6GCVFf_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping as EarlyStopping\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras.layers import Activation\n",
        "print(device_lib.list_local_devices())\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_UGziQ1LuOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/michalovsky/lotr_data.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FNF_i6cF1b7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9dfb11b8-2dd8-4a9b-eb5d-83ae5f6c6e36"
      },
      "source": [
        "file = open('lotr_data/lotr.txt','rt')\n",
        "text = file.read()\n",
        "file.close()\n",
        "\n",
        "#remove unwanted characters\n",
        "chars_to_remove = ['…', '‚', '’', '‘', 'ó', '»', 'µ', '®', '«', '¥', '¤', '¢', '}', '{', '—', '_', '=', ';', '~', '`',\n",
        "                   '#', '!', '\\\"', '#', '&', \"\\'\", '(', ')', ',', '-', '.', '/', ':', '*', '[', ']', '\\\\', '|', '?', '–']\n",
        "\n",
        "for char_to_remove in chars_to_remove:\n",
        "  text = text.replace(char_to_remove, \"\")\n",
        "  \n",
        "#case insensitive\n",
        "text = text.lower()\n",
        "\n",
        "#remove extra spaces\n",
        "text = ' '.join(text.split())\n",
        "\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 2897578 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HCZY-GZGQ14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "89d029ac-aa9f-42ae-bf1e-9d48db63a165"
      },
      "source": [
        "# split text into words\n",
        "words = text.split(\" \")\n",
        "print ('Amount of words: {}'.format(len(words)))\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amount of words: 570370\n",
            "37 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppJ2hrDqGUtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "#encode text from characters to numbers  \n",
        "encoded = np.array([char2idx[ch] for ch in text])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGskc03TGZ--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print unique characters\n",
        "print('{')\n",
        "for char in char2idx:\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4T1FgjiGg8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "sequence_length = 100\n",
        "examples_per_epoch = len(encoded)//sequence_length\n",
        "\n",
        "# Create trainging examples\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded)\n",
        "\n",
        "# Create sequences from dataset\n",
        "sequences = char_dataset.batch(sequence_length+1, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjdTeUmqIkuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#first 10 sentence batches\n",
        "for item in sequences.take(10):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UkKhz-ZJNUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform each sequence into two sequences: input(same as sequence), target (shifted by one index)\n",
        "\n",
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pkz--QEZJY-P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7979da38-afa6-4452-c839-40245f1141c6"
      },
      "source": [
        "# First input data and corresponding target data\n",
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'in a hole in the ground there lived a hobbit not a nasty dirty wet hole filled with the ends of worm'\n",
            "Target data: 'n a hole in the ground there lived a hobbit not a nasty dirty wet hole filled with the ends of worms'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0qPZGAFK5Lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle dataset\n",
        "batch_size = 64\n",
        "steps_per_epoch = examples_per_epoch//batch_size\n",
        "buffer_size = 10000\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9PCsVlDLV2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing the GPU presence before feeding the model to take advantage of the tensorflow GRU gpu implemenation\n",
        "if tf.test.is_gpu_available():\n",
        "  rnn = tf.keras.layers.CuDNNGRU\n",
        "else:\n",
        "  import functools\n",
        "  rnn = functools.partial(\n",
        "    tf.keras.layers.GRU, recurrent_activation='sigmoid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP5shCZiLf6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining function building model with two GRU Rnn layers and output to dense layer \n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "        rnn(rnn_units,\n",
        "            return_sequences=True,\n",
        "            recurrent_initializer='glorot_uniform',\n",
        "            stateful=True),\n",
        "        rnn(rnn_units,\n",
        "            return_sequences=True,\n",
        "            recurrent_initializer='glorot_uniform',\n",
        "            stateful=True),\n",
        "    \n",
        "        tf.keras.layers.Dense(vocab_size)])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA193594MwT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary (amount of unique characters)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzvlR2Z1M5-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build model\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR5QfiXyM-Ud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "027bd288-cb59-4b03-894c-ee86fbe1a714"
      },
      "source": [
        "# Model informations\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "    \n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 37) # (batch_size, sequence_length, vocab_size)\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (64, None, 256)           9472      \n",
            "_________________________________________________________________\n",
            "gru_10 (GRU)                 (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "gru_11 (GRU)                 (64, None, 1024)          6297600   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (64, None, 37)            37925     \n",
            "=================================================================\n",
            "Total params: 10,283,301\n",
            "Trainable params: 10,283,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lbCzzfTOAIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get first predictions\n",
        "\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "\n",
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print(\"Next character predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iaRDzX8Pv4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss function\n",
        "\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6h5D-t_WgG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    optimizer = tf.optimizers.Adam(),\n",
        "    loss = loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DN9MDmbWsRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}