{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "character_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmgy6GCVFf_j",
        "colab_type": "code",
        "outputId": "443e684d-6b3c-4276-8723-fe1b5045f89a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version:\", tf.__version__)\n",
        "from tensorflow.keras.callbacks import EarlyStopping as EarlyStopping\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import string\n",
        "import glob"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Tensorflow version: 2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58JCHK2YiIbN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "15020578-1b00-49ef-cb7a-729921dbfe79"
      },
      "source": [
        "# Devices informations\n",
        "print(\"Devices:\\n\", device_lib.list_local_devices())\n",
        "print(\"GPU:\", tf.test.gpu_device_name())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Devices:\n",
            " [name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 12472054844300253970\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 4828310425430406359\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 4257862428345343190\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 11330053735\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 12212173027285556294\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "]\n",
            "GPU: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_UGziQ1LuOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/michalovsky/books_data.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yOZbDntMiSH",
        "colab_type": "code",
        "outputId": "d4d823a9-790d-476a-acf7-cecd080e4a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Read all file paths from directory\n",
        "directory = \"books_data/kafka/\"\n",
        "file_paths = glob.glob(directory +\"*.txt\")    \n",
        "print(\"Found\", len(file_paths), \"text files in directory:\", directory)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1 text files in directory: books_data/kafka/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NmsP_xHPnRe",
        "colab_type": "code",
        "outputId": "6a9f6876-93b2-4dbf-bc8c-6b988e4a7cac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Extract text from all text files\n",
        "text = \"\"\n",
        "\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, 'r') as file:\n",
        "        file_content = file.read()\n",
        "        #remove file beginning and ending from gutenberg books\n",
        "        file_content = file_content[file_content.find(\"*** START\"):file_content.rfind(\"*** END\")]\n",
        "        #remove file ending from wolnelektury books\n",
        "        file_content = file_content[:file_content.rfind(\"-----\")]\n",
        "        text+=file_content\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 119433 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FNF_i6cF1b7",
        "colab_type": "code",
        "outputId": "b1c39af7-4364-482f-a63e-673cc220772d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Preprocess data\n",
        "\n",
        "punctuation_translator = str.maketrans('–—”„…«»‘’“', '          ', string.punctuation)\n",
        "digits_translator = str.maketrans('', '', string.digits)\n",
        "special_characters_translator = str.maketrans('ąćęłńóśźżäöüæèêéô', 'acelnoszzaoueeeeo', '')\n",
        "\n",
        "# remove redundant characters and translate special characters\n",
        "text = text.lower().translate(punctuation_translator).translate(digits_translator).translate(special_characters_translator)\n",
        "\n",
        "# remove \"tom <number>\" strings \n",
        "text = re.sub(r\"\\ntom\\s(.*)\\n\", \"\", text)\n",
        "\n",
        "# remove \"rozdzial <number>\" strings \n",
        "text = re.sub(r\"\\nrozdzial\\s(.*)\\n\", \"\", text)\n",
        "\n",
        "# remove \"chapter <number>\" strings \n",
        "text = re.sub(r\"\\nchapter\\s(.*)\\n\", \"\", text)\n",
        "\n",
        "# remove \"letter <number>\" strings \n",
        "text = re.sub(r\"\\nletter\\s(.*)\\n\", \"\", text)\n",
        "\n",
        "#remove extra spaces and new lines\n",
        "text = ' '.join(text.split())\n",
        "\n",
        "print ('Length of text after preprocessing: {} characters'.format(len(text)))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text after preprocessing: 115574 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HCZY-GZGQ14",
        "colab_type": "code",
        "outputId": "af1e8526-5ff7-4d6b-84ac-40375ca9374d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# split text into words\n",
        "words = text.split(\" \")\n",
        "print ('Amount of words: {}'.format(len(words)))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amount of words: 22043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppJ2hrDqGUtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "vocab_length = len(vocab)\n",
        "\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "#encode text from characters to numbers  \n",
        "encoded = np.array([char2idx[ch] for ch in text])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGskc03TGZ--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "ef8da732-6d53-4d7f-8655-a976c1320cc6"
      },
      "source": [
        "# Print unique characters\n",
        "print ('{} unique characters:'.format(len(vocab)))\n",
        "\n",
        "print('{')\n",
        "for char in char2idx:\n",
        "    print('  {:4s}:{:3d},'.format(repr(char), char2idx[char]))\n",
        "print('}')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27 unique characters:\n",
            "{\n",
            "  ' ' :  0,\n",
            "  'a' :  1,\n",
            "  'b' :  2,\n",
            "  'c' :  3,\n",
            "  'd' :  4,\n",
            "  'e' :  5,\n",
            "  'f' :  6,\n",
            "  'g' :  7,\n",
            "  'h' :  8,\n",
            "  'i' :  9,\n",
            "  'j' : 10,\n",
            "  'k' : 11,\n",
            "  'l' : 12,\n",
            "  'm' : 13,\n",
            "  'n' : 14,\n",
            "  'o' : 15,\n",
            "  'p' : 16,\n",
            "  'q' : 17,\n",
            "  'r' : 18,\n",
            "  's' : 19,\n",
            "  't' : 20,\n",
            "  'u' : 21,\n",
            "  'v' : 22,\n",
            "  'w' : 23,\n",
            "  'x' : 24,\n",
            "  'y' : 25,\n",
            "  'z' : 26,\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4T1FgjiGg8d",
        "colab_type": "code",
        "outputId": "6b4b6c1e-bb80-4e20-cc28-254f2d12a4fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "sequence_length = 30\n",
        "\n",
        "# Create trainging examples\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "for i in range(0, len(text) - sequence_length, 1):\n",
        "    x_sequence = text[i:i + sequence_length]\n",
        "    y_label = text[i + sequence_length]\n",
        "\n",
        "    # We now convert list of characters to integers based on\n",
        "    # previously and add the values to our lists\n",
        "    x_data.append([char2idx[char] for char in x_sequence])\n",
        "    y_data.append(char2idx[y_label])\n",
        "\n",
        "data_length = len(x_data)\n",
        "print(\"Amount of data\", data_length)\n",
        "X = np.reshape(x_data, (data_length, sequence_length, 1))\n",
        "X = X/float(vocab_length)\n",
        "\n",
        "# one hot encoding\n",
        "y = np_utils.to_categorical(y_data)\n",
        "\n",
        "# char_dataset = tf.data.Dataset.from_tensor_slices(encoded)\n",
        "\n",
        "# # Create sequences from dataset\n",
        "# sequences = char_dataset.batch(sequence_length+1, drop_remainder=True)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amount of data 115544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjdTeUmqIkuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#first 10 sequence batches\n",
        "# for item in sequences.take(10):\n",
        "#   print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UkKhz-ZJNUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform each sequence into two sequences: input(same as sequence), target (shifted by one index)\n",
        "\n",
        "# def split_input_target(chunk):\n",
        "#   input_text = chunk[:-1]\n",
        "#   target_text = chunk[1:]\n",
        "#   return input_text, target_text\n",
        "\n",
        "# dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pkz--QEZJY-P",
        "colab_type": "code",
        "outputId": "30c12473-2608-4501-ce55-ca11bc7a885b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# First input data and corresponding target data\n",
        "# for input_example, target_example in  dataset.take(1):\n",
        "#   print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "#   print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'start of this project gutenber'\n",
            "Target data: 'tart of this project gutenberg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0qPZGAFK5Lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle dataset\n",
        "# batch_size = 64\n",
        "# steps_per_epoch = examples_per_epoch//batch_size\n",
        "# buffer_size = 10000\n",
        "# dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP5shCZiLf6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining function building model with two GRU Rnn layers and output to dense layer \n",
        "# def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "#     model = tf.keras.Sequential([\n",
        "#         tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "#                                   batch_input_shape=[batch_size, None]),\n",
        "#         tf.keras.layers.LSTM(rnn_units,\n",
        "#             return_sequences=True,\n",
        "#             recurrent_initializer='glorot_uniform',\n",
        "#             stateful=True),\n",
        "#         tf.keras.layers.LSTM(rnn_units,\n",
        "#             return_sequences=True,\n",
        "#             recurrent_initializer='glorot_uniform',\n",
        "#             stateful=True),\n",
        "    \n",
        "#         tf.keras.layers.Dense(vocab_size)])\n",
        "#     return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzvlR2Z1M5-r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "36f21ac4-ef02-4348-e5eb-dc2c93293285"
      },
      "source": [
        "# # Length of the vocabulary (amount of unique characters)\n",
        "# vocab_size = len(vocab)\n",
        "\n",
        "# # The embedding dimension\n",
        "# embedding_dim = 256\n",
        "\n",
        "# # Number of RNN units\n",
        "# rnn_units = 1024\n",
        "\n",
        "# # Build model\n",
        "# model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(LSTM(1024, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "# Model informations\n",
        "model.summary()"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_9 (LSTM)                (None, 30, 256)           264192    \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 30, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 30, 1024)          0         \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 256)               1311744   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 27)                6939      \n",
            "=================================================================\n",
            "Total params: 6,829,851\n",
            "Trainable params: 6,829,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iaRDzX8Pv4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Define loss function\n",
        "\n",
        "# def loss(labels, logits):\n",
        "#   return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6h5D-t_WgG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.compile(\n",
        "#     optimizer = tf.optimizers.Adam(),\n",
        "#     loss = loss\n",
        "#     )\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DN9MDmbWsRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=10)\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True)\n",
        "\n",
        "callbacks = [checkpoint_callback, es]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckKUs9m20mXz",
        "colab_type": "code",
        "outputId": "07e16025-f9d1-4085-d1df-ad54116ca555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# batch_size = 64\n",
        "# examples_per_epoch = len(encoded)//sequence_length\n",
        "# steps_per_epoch = examples_per_epoch//batch_size\n",
        "history = model.fit(X, y, epochs=20, validation_split=0.1, batch_size=256, verbose=2, callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 103989 samples, validate on 11555 samples\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rktOFz_d0zAd",
        "colab_type": "code",
        "outputId": "4c944f1b-1126-4bbc-e975-d696c6c2e33c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir) #second param direct file: \"ckpt_50\""
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_20'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ0KMVJo05cM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2pmrJv_07w1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model):\n",
        "  random_index = np.random.randint(0, len(X)-1)\n",
        "  new_string = x_data[random_index]\n",
        "  print(new_string)\n",
        "  print ('random seed data: ', repr(''.join(idx2char[new_string])))\n",
        "\n",
        "  text_generated = []\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(100):\n",
        "      x = np.reshape(new_string, (1, len(new_string), 1))\n",
        "      x = x/float(vocab_length)\n",
        "\n",
        "      index = np.argmax(model.predict(x))\n",
        "      result = idx2char[index]\n",
        "\n",
        "      new_string = np.append(new_string, index)\n",
        "      new_string = new_string[1:len(new_string)]\n",
        "      print(new_string)\n",
        "      text_generated.append(result)\n",
        "\n",
        "  return ''.join(text_generated)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGzq8hGkpgj9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "255f3aae-bae6-451b-d240-b23fd185c74f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Get training loss for the model to see if we converged correctly\n",
        "training_loss = history.history['loss']\n",
        "validation_loss = history.history['val_loss']\n",
        "training_acc = history.history['accuracy']\n",
        "validation_acc = history.history['val_accuracy']\n",
        "\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "f, (a0, a1) = plt.subplots(1, 2, gridspec_kw={'width_ratios': [3, 3]})\n",
        "\n",
        "a0.plot(epoch_count, training_loss, 'r--')\n",
        "a0.plot(epoch_count, validation_loss, 'b-')\n",
        "a0.legend(['Loss'])\n",
        "# a0.xlabel('Epoch')\n",
        "# a0.ylabel('Loss')\n",
        "\n",
        "# f.tight_layout()\n",
        "# f.savefig('grid_figure.pdf')\n",
        "\n",
        "a1.plot(epoch_count, training_acc, 'r--')\n",
        "a1.plot(epoch_count, validation_acc, 'b-')\n",
        "a1.legend(['Accuracy'])\n",
        "# a1.xlabel('Epoch')\n",
        "# a1.ylabel('Loss')\n",
        "\n",
        "# # Visualize loss history\n",
        "# plt.figure(figsize=(16,9))\n",
        "# plt.plot(epoch_count, training_loss, 'r--')\n",
        "# plt.plot(epoch_count, validation_loss, 'b-')\n",
        "# plt.legend(['Training Loss'])\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.show()\n"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fae5e2430f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZcRkB_TprQP",
        "colab_type": "code",
        "outputId": "769b93cb-db8f-4d59-c5aa-40ab91b1746c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(generate_text(model))\n",
        "# margaret tried up the home that noone else way his head kep"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5, 13, 2, 5, 18, 0, 23, 8, 1, 20, 19, 0, 2, 5, 5, 14, 0, 1, 3, 8, 9, 5, 22, 5, 4, 0, 9, 14, 0, 20]\n",
            "random seed data:  'ember whats been achieved in t'\n",
            "[13  2  5 18  0 23  8  1 20 19  0  2  5  5 14  0  1  3  8  9  5 22  5  4\n",
            "  0  9 14  0 20  8]\n",
            "[ 2  5 18  0 23  8  1 20 19  0  2  5  5 14  0  1  3  8  9  5 22  5  4  0\n",
            "  9 14  0 20  8  5]\n",
            "[ 5 18  0 23  8  1 20 19  0  2  5  5 14  0  1  3  8  9  5 22  5  4  0  9\n",
            " 14  0 20  8  5  0]\n",
            "[18  0 23  8  1 20 19  0  2  5  5 14  0  1  3  8  9  5 22  5  4  0  9 14\n",
            "  0 20  8  5  0  6]\n",
            "[ 0 23  8  1 20 19  0  2  5  5 14  0  1  3  8  9  5 22  5  4  0  9 14  0\n",
            " 20  8  5  0  6 12]\n",
            "[23  8  1 20 19  0  2  5  5 14  0  1  3  8  9  5 22  5  4  0  9 14  0 20\n",
            "  8  5  0  6 12 15]\n",
            "[ 8  1 20 19  0  2  5  5 14  0  1  3  8  9  5 22  5  4  0  9 14  0 20  8\n",
            "  5  0  6 12 15 15]\n",
            "[ 1 20 19  0  2  5  5 14  0  1  3  8  9  5 22  5  4  0  9 14  0 20  8  5\n",
            "  0  6 12 15 15 18]\n",
            "[20 19  0  2  5  5 14  0  1  3  8  9  5 22  5  4  0  9 14  0 20  8  5  0\n",
            "  6 12 15 15 18  0]\n",
            "[19  0  2  5  5 14  0  1  3  8  9  5 22  5  4  0  9 14  0 20  8  5  0  6\n",
            " 12 15 15 18  0 20]\n",
            "[ 0  2  5  5 14  0  1  3  8  9  5 22  5  4  0  9 14  0 20  8  5  0  6 12\n",
            " 15 15 18  0 20  8]\n",
            "[ 2  5  5 14  0  1  3  8  9  5 22  5  4  0  9 14  0 20  8  5  0  6 12 15\n",
            " 15 18  0 20  8  5]\n",
            "[ 5  5 14  0  1  3  8  9  5 22  5  4  0  9 14  0 20  8  5  0  6 12 15 15\n",
            " 18  0 20  8  5  0]\n",
            "[ 5 14  0  1  3  8  9  5 22  5  4  0  9 14  0 20  8  5  0  6 12 15 15 18\n",
            "  0 20  8  5  0  3]\n",
            "[14  0  1  3  8  9  5 22  5  4  0  9 14  0 20  8  5  0  6 12 15 15 18  0\n",
            " 20  8  5  0  3 15]\n",
            "[ 0  1  3  8  9  5 22  5  4  0  9 14  0 20  8  5  0  6 12 15 15 18  0 20\n",
            "  8  5  0  3 15 21]\n",
            "[ 1  3  8  9  5 22  5  4  0  9 14  0 20  8  5  0  6 12 15 15 18  0 20  8\n",
            "  5  0  3 15 21  3]\n",
            "[ 3  8  9  5 22  5  4  0  9 14  0 20  8  5  0  6 12 15 15 18  0 20  8  5\n",
            "  0  3 15 21  3  8]\n",
            "[ 8  9  5 22  5  4  0  9 14  0 20  8  5  0  6 12 15 15 18  0 20  8  5  0\n",
            "  3 15 21  3  8  0]\n",
            "[ 9  5 22  5  4  0  9 14  0 20  8  5  0  6 12 15 15 18  0 20  8  5  0  3\n",
            " 15 21  3  8  0  1]\n",
            "[ 5 22  5  4  0  9 14  0 20  8  5  0  6 12 15 15 18  0 20  8  5  0  3 15\n",
            " 21  3  8  0  1 14]\n",
            "[22  5  4  0  9 14  0 20  8  5  0  6 12 15 15 18  0 20  8  5  0  3 15 21\n",
            "  3  8  0  1 14  4]\n",
            "[ 5  4  0  9 14  0 20  8  5  0  6 12 15 15 18  0 20  8  5  0  3 15 21  3\n",
            "  8  0  1 14  4  0]\n",
            "[ 4  0  9 14  0 20  8  5  0  6 12 15 15 18  0 20  8  5  0  3 15 21  3  8\n",
            "  0  1 14  4  0 19]\n",
            "[ 0  9 14  0 20  8  5  0  6 12 15 15 18  0 20  8  5  0  3 15 21  3  8  0\n",
            "  1 14  4  0 19  8]\n",
            "[ 9 14  0 20  8  5  0  6 12 15 15 18  0 20  8  5  0  3 15 21  3  8  0  1\n",
            " 14  4  0 19  8  5]\n",
            "[14  0 20  8  5  0  6 12 15 15 18  0 20  8  5  0  3 15 21  3  8  0  1 14\n",
            "  4  0 19  8  5  0]\n",
            "[ 0 20  8  5  0  6 12 15 15 18  0 20  8  5  0  3 15 21  3  8  0  1 14  4\n",
            "  0 19  8  5  0 19]\n",
            "[20  8  5  0  6 12 15 15 18  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0\n",
            " 19  8  5  0 19 15]\n",
            "[ 8  5  0  6 12 15 15 18  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19\n",
            "  8  5  0 19 15 15]\n",
            "[ 5  0  6 12 15 15 18  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8\n",
            "  5  0 19 15 15 13]\n",
            "[ 0  6 12 15 15 18  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5\n",
            "  0 19 15 15 13  0]\n",
            "[ 6 12 15 15 18  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0\n",
            " 19 15 15 13  0  8]\n",
            "[12 15 15 18  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19\n",
            " 15 15 13  0  8  5]\n",
            "[15 15 18  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15\n",
            " 15 13  0  8  5  0]\n",
            "[15 18  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15\n",
            " 13  0  8  5  0  8]\n",
            "[18  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13\n",
            "  0  8  5  0  8  1]\n",
            "[ 0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0\n",
            "  8  5  0  8  1  4]\n",
            "[20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8\n",
            "  5  0  8  1  4  0]\n",
            "[ 8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5\n",
            "  0  8  1  4  0  2]\n",
            "[ 5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0\n",
            "  8  1  4  0  2  5]\n",
            "[ 0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0  8\n",
            "  1  4  0  2  5  5]\n",
            "[ 3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0  8  1\n",
            "  4  0  2  5  5 14]\n",
            "[15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0  8  1  4\n",
            "  0  2  5  5 14  0]\n",
            "[21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0  8  1  4  0\n",
            "  2  5  5 14  0  1]\n",
            "[ 3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0  8  1  4  0  2\n",
            "  5  5 14  0  1 14]\n",
            "[ 8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0  8  1  4  0  2  5\n",
            "  5 14  0  1 14  4]\n",
            "[ 0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0  8  1  4  0  2  5  5\n",
            " 14  0  1 14  4  0]\n",
            "[ 1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0  8  1  4  0  2  5  5 14\n",
            "  0  1 14  4  0 19]\n",
            "[14  4  0 19  8  5  0 19 15 15 13  0  8  5  0  8  1  4  0  2  5  5 14  0\n",
            "  1 14  4  0 19  8]\n",
            "[ 4  0 19  8  5  0 19 15 15 13  0  8  5  0  8  1  4  0  2  5  5 14  0  1\n",
            " 14  4  0 19  8  5]\n",
            "[ 0 19  8  5  0 19 15 15 13  0  8  5  0  8  1  4  0  2  5  5 14  0  1 14\n",
            "  4  0 19  8  5  0]\n",
            "[19  8  5  0 19 15 15 13  0  8  5  0  8  1  4  0  2  5  5 14  0  1 14  4\n",
            "  0 19  8  5  0 19]\n",
            "[ 8  5  0 19 15 15 13  0  8  5  0  8  1  4  0  2  5  5 14  0  1 14  4  0\n",
            " 19  8  5  0 19  1]\n",
            "[ 5  0 19 15 15 13  0  8  5  0  8  1  4  0  2  5  5 14  0  1 14  4  0 19\n",
            "  8  5  0 19  1 13]\n",
            "[ 0 19 15 15 13  0  8  5  0  8  1  4  0  2  5  5 14  0  1 14  4  0 19  8\n",
            "  5  0 19  1 13  5]\n",
            "[19 15 15 13  0  8  5  0  8  1  4  0  2  5  5 14  0  1 14  4  0 19  8  5\n",
            "  0 19  1 13  5  0]\n",
            "[15 15 13  0  8  5  0  8  1  4  0  2  5  5 14  0  1 14  4  0 19  8  5  0\n",
            " 19  1 13  5  0 20]\n",
            "[15 13  0  8  5  0  8  1  4  0  2  5  5 14  0  1 14  4  0 19  8  5  0 19\n",
            "  1 13  5  0 20  9]\n",
            "[13  0  8  5  0  8  1  4  0  2  5  5 14  0  1 14  4  0 19  8  5  0 19  1\n",
            " 13  5  0 20  9 13]\n",
            "[ 0  8  5  0  8  1  4  0  2  5  5 14  0  1 14  4  0 19  8  5  0 19  1 13\n",
            "  5  0 20  9 13  5]\n",
            "[ 8  5  0  8  1  4  0  2  5  5 14  0  1 14  4  0 19  8  5  0 19  1 13  5\n",
            "  0 20  9 13  5  0]\n",
            "[ 5  0  8  1  4  0  2  5  5 14  0  1 14  4  0 19  8  5  0 19  1 13  5  0\n",
            " 20  9 13  5  0 20]\n",
            "[ 0  8  1  4  0  2  5  5 14  0  1 14  4  0 19  8  5  0 19  1 13  5  0 20\n",
            "  9 13  5  0 20  8]\n",
            "[ 8  1  4  0  2  5  5 14  0  1 14  4  0 19  8  5  0 19  1 13  5  0 20  9\n",
            " 13  5  0 20  8  5]\n",
            "[ 1  4  0  2  5  5 14  0  1 14  4  0 19  8  5  0 19  1 13  5  0 20  9 13\n",
            "  5  0 20  8  5  0]\n",
            "[ 4  0  2  5  5 14  0  1 14  4  0 19  8  5  0 19  1 13  5  0 20  9 13  5\n",
            "  0 20  8  5  0  3]\n",
            "[ 0  2  5  5 14  0  1 14  4  0 19  8  5  0 19  1 13  5  0 20  9 13  5  0\n",
            " 20  8  5  0  3 15]\n",
            "[ 2  5  5 14  0  1 14  4  0 19  8  5  0 19  1 13  5  0 20  9 13  5  0 20\n",
            "  8  5  0  3 15 21]\n",
            "[ 5  5 14  0  1 14  4  0 19  8  5  0 19  1 13  5  0 20  9 13  5  0 20  8\n",
            "  5  0  3 15 21  3]\n",
            "[ 5 14  0  1 14  4  0 19  8  5  0 19  1 13  5  0 20  9 13  5  0 20  8  5\n",
            "  0  3 15 21  3  8]\n",
            "[14  0  1 14  4  0 19  8  5  0 19  1 13  5  0 20  9 13  5  0 20  8  5  0\n",
            "  3 15 21  3  8  0]\n",
            "[ 0  1 14  4  0 19  8  5  0 19  1 13  5  0 20  9 13  5  0 20  8  5  0  3\n",
            " 15 21  3  8  0  1]\n",
            "[ 1 14  4  0 19  8  5  0 19  1 13  5  0 20  9 13  5  0 20  8  5  0  3 15\n",
            " 21  3  8  0  1 14]\n",
            "[14  4  0 19  8  5  0 19  1 13  5  0 20  9 13  5  0 20  8  5  0  3 15 21\n",
            "  3  8  0  1 14  4]\n",
            "[ 4  0 19  8  5  0 19  1 13  5  0 20  9 13  5  0 20  8  5  0  3 15 21  3\n",
            "  8  0  1 14  4  0]\n",
            "[ 0 19  8  5  0 19  1 13  5  0 20  9 13  5  0 20  8  5  0  3 15 21  3  8\n",
            "  0  1 14  4  0 19]\n",
            "[19  8  5  0 19  1 13  5  0 20  9 13  5  0 20  8  5  0  3 15 21  3  8  0\n",
            "  1 14  4  0 19  8]\n",
            "[ 8  5  0 19  1 13  5  0 20  9 13  5  0 20  8  5  0  3 15 21  3  8  0  1\n",
            " 14  4  0 19  8  5]\n",
            "[ 5  0 19  1 13  5  0 20  9 13  5  0 20  8  5  0  3 15 21  3  8  0  1 14\n",
            "  4  0 19  8  5  0]\n",
            "[ 0 19  1 13  5  0 20  9 13  5  0 20  8  5  0  3 15 21  3  8  0  1 14  4\n",
            "  0 19  8  5  0 19]\n",
            "[19  1 13  5  0 20  9 13  5  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0\n",
            " 19  8  5  0 19 15]\n",
            "[ 1 13  5  0 20  9 13  5  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19\n",
            "  8  5  0 19 15 15]\n",
            "[13  5  0 20  9 13  5  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8\n",
            "  5  0 19 15 15 13]\n",
            "[ 5  0 20  9 13  5  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5\n",
            "  0 19 15 15 13  0]\n",
            "[ 0 20  9 13  5  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0\n",
            " 19 15 15 13  0  8]\n",
            "[20  9 13  5  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19\n",
            " 15 15 13  0  8  5]\n",
            "[ 9 13  5  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15\n",
            " 15 13  0  8  5  0]\n",
            "[13  5  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15\n",
            " 13  0  8  5  0  8]\n",
            "[ 5  0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13\n",
            "  0  8  5  0  8  1]\n",
            "[ 0 20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0\n",
            "  8  5  0  8  1  4]\n",
            "[20  8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8\n",
            "  5  0  8  1  4  0]\n",
            "[ 8  5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5\n",
            "  0  8  1  4  0  2]\n",
            "[ 5  0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0\n",
            "  8  1  4  0  2  5]\n",
            "[ 0  3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0  8\n",
            "  1  4  0  2  5  5]\n",
            "[ 3 15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0  8  1\n",
            "  4  0  2  5  5 14]\n",
            "[15 21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0  8  1  4\n",
            "  0  2  5  5 14  0]\n",
            "[21  3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0  8  1  4  0\n",
            "  2  5  5 14  0  1]\n",
            "[ 3  8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0  8  1  4  0  2\n",
            "  5  5 14  0  1 14]\n",
            "[ 8  0  1 14  4  0 19  8  5  0 19 15 15 13  0  8  5  0  8  1  4  0  2  5\n",
            "  5 14  0  1 14  4]\n",
            "he floor the couch and she soom he had been and she same time the couch and she soom he had been and\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}