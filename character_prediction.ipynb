{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "character_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmgy6GCVFf_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "01d12ada-16dd-4813-d70d-37a6f6392cf5"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras.callbacks import EarlyStopping as EarlyStopping\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras.layers import Activation\n",
        "print(device_lib.list_local_devices())\n",
        "print(tf.test.gpu_device_name())\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import string\n",
        "import glob"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 10863907423894129598\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 7447499130611775932\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 16651030693836257992\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 11330115994\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 14506785095655576978\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "]\n",
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_UGziQ1LuOv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "0e099941-7dd8-4cf8-9360-efbd4de0b0ee"
      },
      "source": [
        "!git clone https://github.com/michalovsky/trilogy_data.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'trilogy_data'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 13 (delta 0), reused 8 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (13/13), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yOZbDntMiSH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6165839-f908-40d8-af10-f62b2d7eb2a6"
      },
      "source": [
        "#Read all file paths from directory\n",
        "directory = \"trilogy_data/\"\n",
        "file_paths = glob.glob(directory +\"*.txt\")    \n",
        "print(\"Found\", len(file_paths), \"text files in directory:\", directory)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3 text files in directory: trilogy_data/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NmsP_xHPnRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9bcd4c8e-6d61-496d-9843-6927ef291ffc"
      },
      "source": [
        "# Extract text from all text files\n",
        "text = \"\"\n",
        "\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, 'r') as file:\n",
        "        file_content = file.read()\n",
        "        #remove file beginning\n",
        "        file_content = file_content[file_content.find(\"ISBN\") + len(\"ISBN\"):]\n",
        "        #remove file ending\n",
        "        file_content = file_content[:file_content.rfind(\"-----\")]\n",
        "        text+=file_content\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 2583333 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FNF_i6cF1b7",
        "colab_type": "code",
        "outputId": "8ccbe805-8e38-42c3-98eb-094038f27ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Preprocess data\n",
        "\n",
        "punctuation_translator = str.maketrans('–—”„…«»', '       ', string.punctuation)\n",
        "digits_translator = str.maketrans('', '', string.digits)\n",
        "polish_characters_translator = str.maketrans('ąćęłńóśźż', 'acelnoszz', 'äöü')\n",
        "\n",
        "# remove redundant characters and replace polish characters\n",
        "text = text.lower().translate(punctuation_translator).translate(digits_translator).translate(polish_characters_translator)\n",
        "\n",
        "# remove \"tom <number>\" strings \n",
        "text = re.sub(r\"\\ntom\\s(.*)\\n\", \"\", text)\n",
        "\n",
        "# remove \"rozdzial <number>\" strings \n",
        "text = re.sub(r\"\\nrozdzial\\s(.*)\\n\", \"\", text)\n",
        "\n",
        "#remove extra spaces and new lines\n",
        "text = ' '.join(text.split())\n",
        "\n",
        "print ('Length of text after preprocessing: {} characters'.format(len(text)))\n",
        "\n",
        "vocab = sorted(set(text))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text after preprocessing: 2458504 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HCZY-GZGQ14",
        "colab_type": "code",
        "outputId": "68b431b8-11bb-40f4-f260-0eac672cc281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# split text into words\n",
        "words = text.split(\" \")\n",
        "print ('Amount of words: {}'.format(len(words)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amount of words: 399021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppJ2hrDqGUtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "#encode text from characters to numbers  \n",
        "encoded = np.array([char2idx[ch] for ch in text])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGskc03TGZ--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "69257cea-298d-4069-8bf8-f99373cb16d9"
      },
      "source": [
        "# Print unique characters\n",
        "print ('{} unique characters:'.format(len(vocab)))\n",
        "\n",
        "print('{')\n",
        "for char in char2idx:\n",
        "    print('  {:4s}:{:3d},'.format(repr(char), char2idx[char]))\n",
        "print('}')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27 unique characters:\n",
            "{\n",
            "  ' ' :  0,\n",
            "  'a' :  1,\n",
            "  'b' :  2,\n",
            "  'c' :  3,\n",
            "  'd' :  4,\n",
            "  'e' :  5,\n",
            "  'f' :  6,\n",
            "  'g' :  7,\n",
            "  'h' :  8,\n",
            "  'i' :  9,\n",
            "  'j' : 10,\n",
            "  'k' : 11,\n",
            "  'l' : 12,\n",
            "  'm' : 13,\n",
            "  'n' : 14,\n",
            "  'o' : 15,\n",
            "  'p' : 16,\n",
            "  'q' : 17,\n",
            "  'r' : 18,\n",
            "  's' : 19,\n",
            "  't' : 20,\n",
            "  'u' : 21,\n",
            "  'v' : 22,\n",
            "  'w' : 23,\n",
            "  'x' : 24,\n",
            "  'y' : 25,\n",
            "  'z' : 26,\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4T1FgjiGg8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "sequence_length = 100\n",
        "examples_per_epoch = len(encoded)//sequence_length\n",
        "\n",
        "# Create trainging examples\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded)\n",
        "\n",
        "# Create sequences from dataset\n",
        "sequences = char_dataset.batch(sequence_length+1, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjdTeUmqIkuH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "3f3f2f17-c7ed-492e-df9e-0b80c5aec7f8"
      },
      "source": [
        "#first 10 sequence batches\n",
        "for item in sequences.take(10):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'rok byl to dziwny rok w ktorym rozmaite znaki na niebie i ziemi zwiastowaly jakowes kleski i nadzwycz'\n",
            "'ajne zdarzenia wspolczesni kronikarze wspominaja iz z wiosny szarancza w nieslychanej ilosci wyroila '\n",
            "'sie z dzikich pol i zniszczyla zasiewy i trawy co bylo przepowiednia napadow tatarskich latem zdarzyl'\n",
            "'o sie wielkie zacmienie slonca a wkrotce potem kometa pojawila sie na niebie w warszawie widywano tez'\n",
            "' nad miastem mogile i krzyz ognisty w oblokach odprawiano wiec posty i dawano jalmuzny gdyz niektorzy'\n",
            "' twierdzili ze zaraza spadnie na kraj i wygubi rodzaj ludzki nareszcie zima nastala tak lekka ze najs'\n",
            "'tarsi ludzie nie pamietali podobnej w poludniowych wojewodztwach lody nie popetaly wcale wod ktore po'\n",
            "'dsycane topniejacym kazdego ranka sniegiem wystapily z lozysk i pozalewaly brzegi padaly czeste deszc'\n",
            "'ze step rozmokl i zmienil sie w wielka kaluze slonce zas w poludnie dogrzewalo tak mocno ze dziw nad '\n",
            "'dziwy w wojewodztwie braclawskim i na dzikich polach zielona run okryla stepy i rozlogi juz w polowie'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UkKhz-ZJNUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform each sequence into two sequences: input(same as sequence), target (shifted by one index)\n",
        "\n",
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pkz--QEZJY-P",
        "colab_type": "code",
        "outputId": "4e0bb752-cd27-4540-edf5-96cf0b3efd46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# First input data and corresponding target data\n",
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'rok byl to dziwny rok w ktorym rozmaite znaki na niebie i ziemi zwiastowaly jakowes kleski i nadzwyc'\n",
            "Target data: 'ok byl to dziwny rok w ktorym rozmaite znaki na niebie i ziemi zwiastowaly jakowes kleski i nadzwycz'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0qPZGAFK5Lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle dataset\n",
        "batch_size = 64\n",
        "steps_per_epoch = examples_per_epoch//batch_size\n",
        "buffer_size = 10000\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9PCsVlDLV2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing the GPU presence before feeding the model to take advantage of the tensorflow GRU gpu implemenation\n",
        "if tf.test.is_gpu_available():\n",
        "  rnn = tf.keras.layers.LSTM\n",
        "else:\n",
        "  import functools\n",
        "  rnn = functools.partial(\n",
        "    tf.keras.layers.GRU, recurrent_activation='sigmoid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP5shCZiLf6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining function building model with two GRU Rnn layers and output to dense layer \n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "        rnn(rnn_units,\n",
        "            return_sequences=True,\n",
        "            recurrent_initializer='glorot_uniform',\n",
        "            stateful=True),\n",
        "        rnn(rnn_units,\n",
        "            return_sequences=True,\n",
        "            recurrent_initializer='glorot_uniform',\n",
        "            stateful=True),\n",
        "    \n",
        "        tf.keras.layers.Dense(vocab_size)])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzvlR2Z1M5-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build model\n",
        "\n",
        "# Length of the vocabulary (amount of unique characters)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024\n",
        "\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR5QfiXyM-Ud",
        "colab_type": "code",
        "outputId": "b8c994da-8617-4c4e-f605-ab95e0d40930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# Model informations\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "    \n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 27) # (batch_size, sequence_length, vocab_size)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (64, None, 256)           6912      \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (64, None, 1024)          8392704   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (64, None, 27)            27675     \n",
            "=================================================================\n",
            "Total params: 13,674,267\n",
            "Trainable params: 13,674,267\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lbCzzfTOAIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "6fe9118e-e897-4713-be6c-9e3cb972db1a"
      },
      "source": [
        "# Get first predictions\n",
        "\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "\n",
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print(\"Next character predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " 'ami przed kuznia z gwarem rozmow ze szczekaniem psow widzac to wszystko pan zagloba skrecil zaraz w '\n",
            "Next character predictions: \n",
            " 'qjhngjhukxpzbvlvvessvjodfdhzhphjoqjhgcmgwojndruuadvbnmcjbwk xqkxqpzhznuhwcirfgkgurujintoqhhsrvyyospt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iaRDzX8Pv4T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ad266d81-ed77-40c1-9b41-8eee44442635"
      },
      "source": [
        "# Define loss function\n",
        "\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 27)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       3.2954612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6h5D-t_WgG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    optimizer = tf.optimizers.Adam(),\n",
        "    loss = loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DN9MDmbWsRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "es = EarlyStopping(monitor='loss', mode='min', verbose=2, patience=200)\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fOu1Sdv0juJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckKUs9m20mXz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "24e13f89-a08a-42c5-8dfa-cc68dee2b9e8"
      },
      "source": [
        "history = model.fit(dataset.repeat(), epochs=epochs, steps_per_epoch=steps_per_epoch, verbose=2,callbacks=[checkpoint_callback, es])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 384 steps\n",
            "Epoch 1/200\n",
            "384/384 - 138s - loss: 1.3642\n",
            "Epoch 2/200\n",
            "384/384 - 137s - loss: 1.3127\n",
            "Epoch 3/200\n",
            "384/384 - 137s - loss: 1.2667\n",
            "Epoch 4/200\n",
            "384/384 - 137s - loss: 1.2235\n",
            "Epoch 5/200\n",
            "384/384 - 137s - loss: 1.1782\n",
            "Epoch 6/200\n",
            "384/384 - 137s - loss: 1.1332\n",
            "Epoch 7/200\n",
            "384/384 - 137s - loss: 1.0855\n",
            "Epoch 8/200\n",
            "384/384 - 137s - loss: 1.0356\n",
            "Epoch 9/200\n",
            "384/384 - 137s - loss: 0.9863\n",
            "Epoch 10/200\n",
            "384/384 - 137s - loss: 0.9371\n",
            "Epoch 11/200\n",
            "384/384 - 137s - loss: 0.8877\n",
            "Epoch 12/200\n",
            "384/384 - 137s - loss: 0.8422\n",
            "Epoch 13/200\n",
            "384/384 - 137s - loss: 0.7983\n",
            "Epoch 14/200\n",
            "384/384 - 137s - loss: 0.7588\n",
            "Epoch 15/200\n",
            "384/384 - 137s - loss: 0.7214\n",
            "Epoch 16/200\n",
            "384/384 - 137s - loss: 0.6897\n",
            "Epoch 17/200\n",
            "384/384 - 137s - loss: 0.6591\n",
            "Epoch 18/200\n",
            "384/384 - 137s - loss: 0.6327\n",
            "Epoch 19/200\n",
            "384/384 - 137s - loss: 0.6096\n",
            "Epoch 20/200\n",
            "384/384 - 137s - loss: 0.5907\n",
            "Epoch 21/200\n",
            "384/384 - 137s - loss: 0.5732\n",
            "Epoch 22/200\n",
            "384/384 - 137s - loss: 0.5586\n",
            "Epoch 23/200\n",
            "384/384 - 137s - loss: 0.5457\n",
            "Epoch 24/200\n",
            "384/384 - 137s - loss: 0.5336\n",
            "Epoch 25/200\n",
            "384/384 - 137s - loss: 0.5241\n",
            "Epoch 26/200\n",
            "384/384 - 137s - loss: 0.5163\n",
            "Epoch 27/200\n",
            "384/384 - 137s - loss: 0.5097\n",
            "Epoch 28/200\n",
            "384/384 - 137s - loss: 0.5041\n",
            "Epoch 29/200\n",
            "384/384 - 137s - loss: 0.4969\n",
            "Epoch 30/200\n",
            "384/384 - 137s - loss: 0.4925\n",
            "Epoch 31/200\n",
            "384/384 - 137s - loss: 0.4879\n",
            "Epoch 32/200\n",
            "384/384 - 137s - loss: 0.4858\n",
            "Epoch 33/200\n",
            "384/384 - 137s - loss: 0.4815\n",
            "Epoch 34/200\n",
            "384/384 - 137s - loss: 0.4785\n",
            "Epoch 35/200\n",
            "384/384 - 137s - loss: 0.4769\n",
            "Epoch 36/200\n",
            "384/384 - 137s - loss: 0.4738\n",
            "Epoch 37/200\n",
            "384/384 - 137s - loss: 0.4726\n",
            "Epoch 38/200\n",
            "384/384 - 137s - loss: 0.4698\n",
            "Epoch 39/200\n",
            "384/384 - 137s - loss: 0.4665\n",
            "Epoch 40/200\n",
            "384/384 - 137s - loss: 0.4665\n",
            "Epoch 41/200\n",
            "384/384 - 136s - loss: 0.4658\n",
            "Epoch 42/200\n",
            "384/384 - 136s - loss: 0.4648\n",
            "Epoch 43/200\n",
            "384/384 - 137s - loss: 0.4643\n",
            "Epoch 44/200\n",
            "384/384 - 137s - loss: 0.4635\n",
            "Epoch 45/200\n",
            "384/384 - 137s - loss: 0.4626\n",
            "Epoch 46/200\n",
            "384/384 - 137s - loss: 0.4606\n",
            "Epoch 47/200\n",
            "384/384 - 137s - loss: 0.4606\n",
            "Epoch 48/200\n",
            "384/384 - 137s - loss: 0.4609\n",
            "Epoch 49/200\n",
            "384/384 - 136s - loss: 0.4614\n",
            "Epoch 50/200\n",
            "384/384 - 137s - loss: 0.4584\n",
            "Epoch 51/200\n",
            "384/384 - 137s - loss: 0.4596\n",
            "Epoch 52/200\n",
            "384/384 - 137s - loss: 0.4598\n",
            "Epoch 53/200\n",
            "384/384 - 137s - loss: 0.4598\n",
            "Epoch 54/200\n",
            "384/384 - 137s - loss: 0.4593\n",
            "Epoch 55/200\n",
            "384/384 - 137s - loss: 0.4591\n",
            "Epoch 56/200\n",
            "384/384 - 137s - loss: 0.4578\n",
            "Epoch 57/200\n",
            "384/384 - 137s - loss: 0.4588\n",
            "Epoch 58/200\n",
            "384/384 - 137s - loss: 0.4614\n",
            "Epoch 59/200\n",
            "384/384 - 137s - loss: 0.4603\n",
            "Epoch 60/200\n",
            "384/384 - 137s - loss: 0.4612\n",
            "Epoch 61/200\n",
            "384/384 - 137s - loss: 0.4610\n",
            "Epoch 62/200\n",
            "384/384 - 137s - loss: 0.4619\n",
            "Epoch 63/200\n",
            "384/384 - 137s - loss: 0.4608\n",
            "Epoch 64/200\n",
            "384/384 - 137s - loss: 0.4627\n",
            "Epoch 65/200\n",
            "384/384 - 136s - loss: 0.4609\n",
            "Epoch 66/200\n",
            "384/384 - 136s - loss: 0.4640\n",
            "Epoch 67/200\n",
            "384/384 - 137s - loss: 0.4649\n",
            "Epoch 68/200\n",
            "384/384 - 137s - loss: 0.4652\n",
            "Epoch 69/200\n",
            "384/384 - 137s - loss: 0.4662\n",
            "Epoch 70/200\n",
            "384/384 - 137s - loss: 0.4668\n",
            "Epoch 71/200\n",
            "384/384 - 137s - loss: 0.4665\n",
            "Epoch 72/200\n",
            "384/384 - 136s - loss: 0.4685\n",
            "Epoch 73/200\n",
            "384/384 - 137s - loss: 0.4676\n",
            "Epoch 74/200\n",
            "384/384 - 137s - loss: 0.4704\n",
            "Epoch 75/200\n",
            "384/384 - 137s - loss: 0.4715\n",
            "Epoch 76/200\n",
            "384/384 - 137s - loss: 0.4713\n",
            "Epoch 77/200\n",
            "384/384 - 136s - loss: 0.4737\n",
            "Epoch 78/200\n",
            "384/384 - 137s - loss: 0.4734\n",
            "Epoch 79/200\n",
            "384/384 - 137s - loss: 0.4753\n",
            "Epoch 80/200\n",
            "384/384 - 137s - loss: 0.4776\n",
            "Epoch 81/200\n",
            "384/384 - 136s - loss: 0.4792\n",
            "Epoch 82/200\n",
            "384/384 - 136s - loss: 0.4797\n",
            "Epoch 83/200\n",
            "384/384 - 137s - loss: 0.4785\n",
            "Epoch 84/200\n",
            "384/384 - 137s - loss: 0.4802\n",
            "Epoch 85/200\n",
            "384/384 - 137s - loss: 0.4820\n",
            "Epoch 86/200\n",
            "384/384 - 137s - loss: 0.4840\n",
            "Epoch 87/200\n",
            "384/384 - 137s - loss: 0.4855\n",
            "Epoch 88/200\n",
            "384/384 - 137s - loss: 0.4877\n",
            "Epoch 89/200\n",
            "384/384 - 137s - loss: 0.4897\n",
            "Epoch 90/200\n",
            "384/384 - 137s - loss: 0.4925\n",
            "Epoch 91/200\n",
            "384/384 - 137s - loss: 0.4932\n",
            "Epoch 92/200\n",
            "384/384 - 137s - loss: 0.4922\n",
            "Epoch 93/200\n",
            "384/384 - 137s - loss: 0.4962\n",
            "Epoch 94/200\n",
            "384/384 - 137s - loss: 0.4956\n",
            "Epoch 95/200\n",
            "384/384 - 136s - loss: 0.4979\n",
            "Epoch 96/200\n",
            "384/384 - 138s - loss: 0.4991\n",
            "Epoch 97/200\n",
            "384/384 - 136s - loss: 0.5002\n",
            "Epoch 98/200\n",
            "384/384 - 136s - loss: 0.5045\n",
            "Epoch 99/200\n",
            "384/384 - 137s - loss: 0.5051\n",
            "Epoch 100/200\n",
            "384/384 - 137s - loss: 0.5063\n",
            "Epoch 101/200\n",
            "384/384 - 137s - loss: 0.5064\n",
            "Epoch 102/200\n",
            "384/384 - 137s - loss: 0.5094\n",
            "Epoch 103/200\n",
            "384/384 - 137s - loss: 0.5112\n",
            "Epoch 104/200\n",
            "384/384 - 137s - loss: 0.5105\n",
            "Epoch 105/200\n",
            "384/384 - 137s - loss: 0.5147\n",
            "Epoch 106/200\n",
            "384/384 - 137s - loss: 0.5182\n",
            "Epoch 107/200\n",
            "384/384 - 137s - loss: 0.5199\n",
            "Epoch 108/200\n",
            "384/384 - 137s - loss: 0.5225\n",
            "Epoch 109/200\n",
            "384/384 - 137s - loss: 0.5245\n",
            "Epoch 110/200\n",
            "384/384 - 137s - loss: 0.5245\n",
            "Epoch 111/200\n",
            "384/384 - 137s - loss: 0.5278\n",
            "Epoch 112/200\n",
            "384/384 - 137s - loss: 0.5314\n",
            "Epoch 113/200\n",
            "384/384 - 137s - loss: 0.5343\n",
            "Epoch 114/200\n",
            "384/384 - 137s - loss: 0.5370\n",
            "Epoch 115/200\n",
            "384/384 - 137s - loss: 0.5397\n",
            "Epoch 116/200\n",
            "384/384 - 137s - loss: 0.5424\n",
            "Epoch 117/200\n",
            "384/384 - 137s - loss: 0.5436\n",
            "Epoch 118/200\n",
            "384/384 - 137s - loss: 0.5453\n",
            "Epoch 119/200\n",
            "384/384 - 137s - loss: 0.5489\n",
            "Epoch 120/200\n",
            "384/384 - 137s - loss: 0.5517\n",
            "Epoch 121/200\n",
            "384/384 - 137s - loss: 0.5546\n",
            "Epoch 122/200\n",
            "384/384 - 137s - loss: 0.5589\n",
            "Epoch 123/200\n",
            "384/384 - 137s - loss: 0.5637\n",
            "Epoch 124/200\n",
            "384/384 - 137s - loss: 0.5658\n",
            "Epoch 125/200\n",
            "384/384 - 137s - loss: 0.5692\n",
            "Epoch 126/200\n",
            "384/384 - 136s - loss: 0.5729\n",
            "Epoch 127/200\n",
            "384/384 - 137s - loss: 0.5760\n",
            "Epoch 128/200\n",
            "384/384 - 136s - loss: 0.5770\n",
            "Epoch 129/200\n",
            "384/384 - 136s - loss: 0.5806\n",
            "Epoch 130/200\n",
            "384/384 - 136s - loss: 0.5864\n",
            "Epoch 131/200\n",
            "384/384 - 136s - loss: 0.5920\n",
            "Epoch 132/200\n",
            "384/384 - 136s - loss: 0.5948\n",
            "Epoch 133/200\n",
            "384/384 - 136s - loss: 0.5954\n",
            "Epoch 134/200\n",
            "384/384 - 136s - loss: 0.5990\n",
            "Epoch 135/200\n",
            "384/384 - 137s - loss: 0.6036\n",
            "Epoch 136/200\n",
            "384/384 - 137s - loss: 0.6079\n",
            "Epoch 137/200\n",
            "384/384 - 136s - loss: 0.6144\n",
            "Epoch 138/200\n",
            "384/384 - 137s - loss: 0.6200\n",
            "Epoch 139/200\n",
            "384/384 - 137s - loss: 0.6225\n",
            "Epoch 140/200\n",
            "384/384 - 137s - loss: 0.6310\n",
            "Epoch 141/200\n",
            "384/384 - 136s - loss: 0.6353\n",
            "Epoch 142/200\n",
            "384/384 - 136s - loss: 0.6412\n",
            "Epoch 143/200\n",
            "384/384 - 137s - loss: 0.6452\n",
            "Epoch 144/200\n",
            "384/384 - 137s - loss: 0.6505\n",
            "Epoch 145/200\n",
            "384/384 - 137s - loss: 0.6558\n",
            "Epoch 146/200\n",
            "384/384 - 136s - loss: 0.6613\n",
            "Epoch 147/200\n",
            "384/384 - 136s - loss: 0.6693\n",
            "Epoch 148/200\n",
            "384/384 - 136s - loss: 0.6740\n",
            "Epoch 149/200\n",
            "384/384 - 136s - loss: 0.6788\n",
            "Epoch 150/200\n",
            "384/384 - 137s - loss: 0.6844\n",
            "Epoch 151/200\n",
            "384/384 - 137s - loss: 0.6898\n",
            "Epoch 152/200\n",
            "384/384 - 136s - loss: 0.6981\n",
            "Epoch 153/200\n",
            "384/384 - 136s - loss: 0.7060\n",
            "Epoch 154/200\n",
            "384/384 - 136s - loss: 0.7136\n",
            "Epoch 155/200\n",
            "384/384 - 136s - loss: 0.7233\n",
            "Epoch 156/200\n",
            "384/384 - 136s - loss: 0.7280\n",
            "Epoch 157/200\n",
            "384/384 - 136s - loss: 0.7349\n",
            "Epoch 158/200\n",
            "384/384 - 136s - loss: 0.7445\n",
            "Epoch 159/200\n",
            "384/384 - 136s - loss: 0.7480\n",
            "Epoch 160/200\n",
            "384/384 - 136s - loss: 0.7565\n",
            "Epoch 161/200\n",
            "384/384 - 136s - loss: 0.7666\n",
            "Epoch 162/200\n",
            "384/384 - 136s - loss: 0.7784\n",
            "Epoch 163/200\n",
            "384/384 - 136s - loss: 0.7847\n",
            "Epoch 164/200\n",
            "384/384 - 136s - loss: 0.7926\n",
            "Epoch 165/200\n",
            "384/384 - 136s - loss: 0.8038\n",
            "Epoch 166/200\n",
            "384/384 - 136s - loss: 0.8118\n",
            "Epoch 167/200\n",
            "384/384 - 136s - loss: 0.8222\n",
            "Epoch 168/200\n",
            "384/384 - 136s - loss: 0.8365\n",
            "Epoch 169/200\n",
            "384/384 - 136s - loss: 0.8455\n",
            "Epoch 170/200\n",
            "384/384 - 136s - loss: 0.8580\n",
            "Epoch 171/200\n",
            "384/384 - 136s - loss: 0.8711\n",
            "Epoch 172/200\n",
            "384/384 - 136s - loss: 0.8854\n",
            "Epoch 173/200\n",
            "384/384 - 136s - loss: 0.8922\n",
            "Epoch 174/200\n",
            "384/384 - 136s - loss: 0.9067\n",
            "Epoch 175/200\n",
            "384/384 - 136s - loss: 0.9181\n",
            "Epoch 176/200\n",
            "384/384 - 136s - loss: 0.9318\n",
            "Epoch 177/200\n",
            "384/384 - 136s - loss: 0.9463\n",
            "Epoch 178/200\n",
            "384/384 - 136s - loss: 0.9574\n",
            "Epoch 179/200\n",
            "384/384 - 136s - loss: 0.9696\n",
            "Epoch 180/200\n",
            "384/384 - 136s - loss: 0.9893\n",
            "Epoch 181/200\n",
            "384/384 - 136s - loss: 1.0036\n",
            "Epoch 182/200\n",
            "384/384 - 136s - loss: 1.0231\n",
            "Epoch 183/200\n",
            "384/384 - 136s - loss: 1.0331\n",
            "Epoch 184/200\n",
            "384/384 - 136s - loss: 1.0453\n",
            "Epoch 185/200\n",
            "384/384 - 136s - loss: 1.0655\n",
            "Epoch 186/200\n",
            "384/384 - 136s - loss: 1.1035\n",
            "Epoch 187/200\n",
            "384/384 - 136s - loss: 1.1206\n",
            "Epoch 188/200\n",
            "384/384 - 136s - loss: 1.1384\n",
            "Epoch 189/200\n",
            "384/384 - 136s - loss: 1.1434\n",
            "Epoch 190/200\n",
            "384/384 - 136s - loss: 1.1545\n",
            "Epoch 191/200\n",
            "384/384 - 138s - loss: 1.1773\n",
            "Epoch 192/200\n",
            "384/384 - 136s - loss: 1.1917\n",
            "Epoch 193/200\n",
            "384/384 - 136s - loss: 1.2044\n",
            "Epoch 194/200\n",
            "384/384 - 136s - loss: 1.2092\n",
            "Epoch 195/200\n",
            "384/384 - 136s - loss: 1.2247\n",
            "Epoch 196/200\n",
            "384/384 - 136s - loss: 1.2521\n",
            "Epoch 197/200\n",
            "384/384 - 136s - loss: 1.2619\n",
            "Epoch 198/200\n",
            "384/384 - 136s - loss: 1.2702\n",
            "Epoch 199/200\n",
            "384/384 - 136s - loss: 1.2816\n",
            "Epoch 200/200\n",
            "384/384 - 136s - loss: 1.2956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rktOFz_d0zAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir, \"ckpt_50\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ0KMVJo05cM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2pmrJv_07w1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 1000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a multinomial distribution to predict the word returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted word as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tzNuLtjpcSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f87dbaf6-6a97-472d-b8c7-960a4c11d24d"
      },
      "source": [
        "#history.history will track the models metrics during training and can be accessed in key value pairs\n",
        "#this model is only currently tracking training loss but could be expanded to include others with the \n",
        "#call back method.\n",
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGzq8hGkpgj9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "bdccfaad-3159-4344-b091-47ecef21c4b6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Get training loss for the model to see if we converged correctly\n",
        "training_loss = history.history['loss']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.plot(epoch_count, training_loss, 'r--')\n",
        "#plt.plot(epoch_count, test_loss, 'b-')\n",
        "plt.legend(['Training Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7AAAAIWCAYAAABuj2GFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzde/zX8/3/8duzc6RaB0SSM32qT/Jh\nmlOWWc4zIVbY17QZ5jS/tTGMMV+H74ZlpomxyQzDiJyZJXyK0kFKsY4OEUmlT71+fzwLo8OnPu/3\n5/k+3K6Xy/vy+hzefT73y7Q+n/v7+Xw9niHLMiRJkiRJKnQNUgeQJEmSJKk2LLCSJEmSpKJggZUk\nSZIkFQULrCRJkiSpKFhgJUmSJElFwQIrSZIkSSoKjVIHWF/t2rXLOnfunDqGJEmSJCkPxowZ816W\nZe1X97m8FdgQwjDgUOCdLMu6ruV5uwPPA/2zLLt7XV+3c+fOVFdX5y6oJEmSJKlghBDeWtPn8rmF\n+Fag79qeEEJoCPwv8Ggec0iSJEmSSkDeCmyWZc8C76/jaWcA9wDv5CuHJEmSJKk0JBviFELYEjgS\n+EMtnjsohFAdQqh+99138x9OkiRJklRwUg5x+h3wsyzLVoQQ1vrELMtuAm4CqKqqyuohmyRJkqQS\nsmzZMmbNmsWSJUtSR9FKzZo1o2PHjjRu3LjWfyZlga0C7lxZXtsBB4cQarIsuy9hJkmSJEklaNas\nWWyyySZ07tyZdS2gKf+yLGP+/PnMmjWLbbbZptZ/LlmBzbLss5QhhFuBBy2vkiRJkvJhyZIlltcC\nEkKgbdu2rO8tovk8Rmc40BtoF0KYBVwENAbIsuzGfH1fSZIkSVody2th2ZD/HvmcQnxclmUdsixr\nnGVZxyzLbs6y7MbVldcsy06qzRmwkiRJklSM5s+fT48ePejRowebb745W2655Wfvf/rpp7X6Gt//\n/veZMmXKWp8zZMgQ/vrXv+YiMnvvvTevvPJKTr5WrqS8B1aSJEmSykLbtm0/K4MXX3wxLVq04Kc/\n/el/PSfLMrIso0GD1a8z3nLLLev8PqeddlrdwxawZMfoSJIkSVK5mzZtGl26dOF73/seFRUVzJ07\nl0GDBlFVVUVFRQWXXHLJZ89dtSJaU1ND69atGTx4MJWVlfTq1Yt33nkHgAsuuIDf/e53nz1/8ODB\n7LHHHuy0006MGjUKgEWLFnHUUUfRpUsX+vXrR1VVVa1XWhcvXsyJJ55It27d6NmzJ88++ywAr776\nKrvvvjs9evSge/fuTJ8+nYULF3LQQQdRWVlJ165dufvuum+6dQVWkiRJUvnp3furHzvmGPjxj+GT\nT+Dgg7/6+ZNOio/33oN+/f77c08/vcFRXnvtNW677TaqqqoAuOKKK2jTpg01NTXsv//+9OvXjy5d\nuvzXn/nwww/Zb7/9uOKKKzjnnHMYNmwYgwcP/srXzrKMF198kQceeIBLLrmERx55hOuvv57NN9+c\ne+65h3HjxtGzZ89aZ73uuuto2rQpr776KhMnTuTggw9m6tSp3HDDDfz0pz/l2GOPZenSpWRZxv33\n30/nzp15+OGHP8tcV67ASpIkSVJC22233WflFWD48OH07NmTnj17MnnyZCZNmvSVP9O8eXMOOugg\nAHbbbTfefPPN1X7t7373u195znPPPUf//v0BqKyspKKiotZZn3vuOQYMGABARUUFW2yxBdOmTeMb\n3/gGv/71r7nyyiuZOXMmzZo1o3v37jzyyCMMHjyYf//737Rq1arW32dNXIGVJEmSVH7WtmK60UZr\n/3y7dnVacf2yjTfe+LO3p06dyrXXXsuLL75I69atGTBgAEuWLPnKn2nSpMlnbzds2JCamprVfu2m\nTZuu8zm5MHDgQHr16sVDDz1E3759GTZsGPvuuy/V1dWMGDGCwYMHc9BBB/GLX/yiTt/HFVhJkiRJ\nKhAfffQRm2yyCS1btmTu3LmMHDky599jr7324q677gLivaurW+Fdk3322eezKceTJ09m7ty5bL/9\n9kyfPp3tt9+eM888k0MPPZTx48cze/ZsWrRowcCBAzn33HMZO3ZsnbO7AitJkiRJBaJnz5506dKF\nnXfema233pq99tor59/jjDPO4IQTTqBLly6fPda0vffb3/42jRs3BmJ5HTZsGD/84Q/p1q0bjRs3\n5rbbbqNJkybccccdDB8+nMaNG7PFFltw8cUXM2rUKAYPHkyDBg1o0qQJN974lRNV11vIsqzOX6Q+\nVVVVZdXV1aljSJIkSSoikydPZpdddkkdoyDU1NRQU1NDs2bNmDp1KgceeCBTp06lUaP6X99c3X+X\nEMKYLMuqVvd8V2AlSZIkqYx8/PHH9OnTh5qaGrIs449//GOS8rohiiOlJEmSJCknWrduzZgxY1LH\n2CAOcZIkSZIkFQULbK699lp8SJIkSSooxTb/p9RtyH8PC2yuHXwwXHxx6hSSJEmSvqBZs2bMnz/f\nElsgsixj/vz5NGvWbL3+nPfA5touu8DkyalTSJIkSfqCjh07MmvWLN59993UUbRSs2bN6Nix43r9\nGQtsrnXpAk88AcuXQ8OGqdNIkiRJAho3bsw222yTOobqyC3EubbLLrB0KcyYkTqJJEmSJJUUC2yu\nrTqE123EkiRJkpRTFthc694d7r8fevVKnUSSJEmSSor3wObaxhvD4YenTiFJkiRJJccV2HwYMwbu\nvDN1CkmSJEkqKRbYfLjlFhg0CDxjSpIkSZJyxgKbD126wMKFMGdO6iSSJEmSVDIssPngJGJJkiRJ\nyjkLbD6sKrCTJqXNIUmSJEklxAKbD5ttBq1buwIrSZIkSTnkMTr5EAKMHg0dO6ZOIkmSJEklwwKb\nLzvtlDqBJEmSJJUUtxDny4QJ8P/+H3zwQeokkiRJklQSLLD5MnMmXHUVTJyYOokkSZIklQQLbL44\niViSJEmScsoCmy+dOsFGGzmJWJIkSZJyxAKbLw0axEFOFlhJkiRJygkLbD516QLz5qVOIUmSJEkl\nwWN08unmm6FJk9QpJEmSJKkkWGDzqWnT1AkkSZIkqWS4hTifPvgAvvc9eOih1EkkSZIkqehZYPOp\nRQu46y74179SJ5EkSZKkomeBzafGjeMk4okTUyeRJEmSpKJngc237t1h/PjUKSRJkiSp6Flg862y\nEv7zH1iwIHUSSZIkSSpqFth869kzrsK+/XbqJJIkSZJU1DxGJ9++9S0YNy51CkmSJEkqeq7ASpIk\nSZKKggW2PpxzDhx8cOoUkiRJklTULLD1YcUKeOaZeJUkSZIkbRALbH3o3h0++QTeeCN1EkmSJEnl\n6qqr4KKLinphzQJbH7p3j1fPg5UkSZKUwltvxfI6eTI0KN4aWLzJi0lFRfxLYoGVJEmSlMK558br\n1VenzVFHFtj60Lw5nHwybL996iSSJEmSys3jj8M998D550OnTqnT1EnIsix1hvVSVVWVVVdXp44h\nSZIkSYUvy+ItjYsXw4QJ0KxZ6kTrFEIYk2VZ1eo+16i+w5S1Tz6Bxo3jQ5IkSZLyLQT4y19g4cKi\nKK/r4hbi+vLEE9CiBbz0UuokkiRJksrB8uXxWlkJe++dNkuOWGDryw47xOV7BzlJkiRJyrcVK+Dw\nw2HQoNhDSoQFtr5stRW0bg3jxqVOIkmSJKnUXXstjBgBPXrEbcQlwgJbX0KIN0+7AitJkiQpn8aM\ngZ/9DL7zHTj11NRpcsoCW5+6d4dXX43L+ZIkSZKUawsXQv/+sNlmcPPNJbX6Ck4hrl9HHx3vhV22\nDJo2TZ1GkiRJUqmZMAHmz4f77oM2bVKnyTkLbH3ad9/4kCRJkqR86NUL3noLNtkkdZK8cAtxfZsx\nA6ZMSZ1CkiRJUim55Ra4+ur4domWV7DA1r9vfxt+8YvUKSRJkiSViltugZNPhsce+/zs1xJlga1v\nPXrAyy+nTiFJkiSpFKwqrwccEO97bdgwdaK8ssDWt5494zbiBQtSJ5EkSZJUzP7618/L6/33Q/Pm\nqRPlnQW2vu26a7y+8kraHJIkSZKK20cfQZ8+ZVNewQJb/1YV2LFj0+aQJEmSVJxWrIjXU0+FkSPL\npryCBbb+bbop3HsvHHts6iSSJEmSis38+VBVBQ8/HN9vUF6VznNgUzjyyNQJJEmSJBWbTz+F734X\nJk6Eli1Tp0mivOp6oXjrLRgyBD75JHUSSZIkScXil7+EZ5+Nk4f32it1miQssCmMHQunnw6vvpo6\niSRJkqRikGVx6vARR8Dxx6dOk4wFNoWePePV82AlSZIk1caECTB7dtnfjug9sCl06gRf+5qTiCVJ\nkiTVTrduMHVqHApbxiywKYQQj9NxBVaSJElSbW2/feoEybmFOJWePeP0sJqa1EkkSZIkFbKZM+Mx\nnBMnpk6SnAU2lZ/9DObNg0YugkuSJElai3/+E+66q+zOfF0d21Mq7dqlTiBJkiSpGPzzn3H78M47\np06SnBU+pcsvh6FDU6eQJEmSVKgWLoQnn4TDD4+zdMqcBTalBx+Ev/wldQpJkiRJheqxx+DTT2OB\nlQU2qVWTiFesSJ1EkiRJUiFavhz23BP22it1koJggU2pZ8+4JWD69NRJJEmSJBWio4+G5593+OtK\nFtiUdt01Xj0PVpIkSdKXffghLFuWOkVBscCmVFEBbdvC/Pmpk0iSJEkqNJdfDltsAUuXpk5SMFyH\nTqlpU3j3XaeJSZIkSfpvH30Ew4bBHnvE3iDAFdj0LK+SJEmSvuyaa+C99+Dii1MnKSgW2NQeewx2\n2w3mzUudRJIkSVIhePvtWGD79YPdd0+dpqBYYFNr1AjGjoVx41InkSRJklQI7roLliyByy5LnaTg\nWGBTq6yMVwusJEmSJIAzzoCJE2HHHVMnKTgW2NTatIGOHS2wkiRJkuD99+N1p53S5ihQFthCUFlp\ngZUkSZLK3csvw5ZbwsMPp05SsCywheDb344lNstSJ5EkSZKUwpgxcOKJsNFG8I1vpE5TsCywheCM\nM+Cvf/VIHUmSJKnczJsHJ58cpw3Pmwe33gqtWqVOVbDyVmBDCMNCCO+EECas4fPfCyGMDyG8GkIY\nFUKozFeWorFsWeoEkiRJkurTlCnwl7/AuefC1Klw2GGpExW0fK7A3gr0XcvnZwD7ZVnWDbgUuCmP\nWQpblsEOO8B556VOIkmSJKk+fPppvO63H7z1Flx1lSuvtZC3Aptl2bPA+2v5/Kgsyz5Y+e5ooGO+\nshS8EKBtWwc5SZIkSeVg8WLYdVe47rr4/uabp81TRArlHtiTgTWO2gohDAohVIcQqt999916jFWP\nVk0idpCTJEmSVNouuggmTYKKitRJik7yAhtC2J9YYH+2pudkWXZTlmVVWZZVtW/fvv7C1afKSvjg\nA5g1K3USSZIkSfny0ktwzTVwyinQp0/qNEUnaYENIXQH/gQckWXZ/JRZkqtcOcPKbcSSJElSaVq6\nFL7/fejQId7zqvXWKNU3DiF0Au4FBmZZ9nqqHAWje3c46yzYaqvUSSRJkiTlw6hR8Prr8I9/OLBp\nA4UsT/dchhCGA72BdsDbwEVAY4Asy24MIfwJOAp4a+UfqcmyrGpdX7eqqiqrrq7OS2ZJkiRJyquZ\nM120WocQwpg1dcO8rcBmWXbcOj7/A+AH+fr+RenTT2HaNOjSJXUSSZIkSbn0yivQo4fltY6SD3HS\nF1xxBXTtCh9/nDqJJEmSpFx59NF4bM6996ZOUvQssIWksjIeo/Pqq6mTSJIkScqFZcvg7LNhu+3g\nkENSpyl6FthC4iRiSZIkqbTceGM88/Waa6Bp09Rpip4FtpBsvXWcRmaBlSRJkorf/Plw0UXxvNfD\nD0+dpiRYYAtJCPE4HQusJEmSVPwmToTGjeG3v42/66vOkp0DqzW48EJo2DB1CkmSJEl1te++8NZb\n0KxZ6iQlwwJbaA44IHUCSZIkSXU1cyZssYXlNcfcQlxoPv0UHn4YXnstdRJJkiRJG+rQQ+GII1Kn\nKDkW2EKzfHn8y37HHamTSJIkSdoQ48fHR9++qZOUHAtsoWneHHbayUFOkiRJUrG6/XZo1Aj690+d\npORYYAtRZaUFVpIkSSpGy5fH3ZQHHwzt2qVOU3IssIWosjJOK1uwIHUSSZIkSevj6adhzhwYODB1\nkpJkgS1EPXrE6/jxaXNIkiRJWj+9e8PIkXGujXLOY3QK0d57x/K6886pk0iSJElaHw0bwoEHpk5R\nslyBLUQtWkC3btC4ceokkiRJkmrr/vvhvPPgk09SJylZFthCNXIkXHll6hSSJEmSamvIELjnHmjW\nLHWSkmWBLVSPPQYXXgg1NamTSJIkSVqXcePg8cdhwABoYM3KF/+XLVSVlbB0Kbz+euokkiRJktZm\n4UI4+mjYfHM444zUaUqaBbZQVVbGq+fBSpIkSYXtvPPgjTdg+HBo3z51mpJmgS1UO+8chzi98krq\nJJIkSZLW5vzz4c9/hv32S52k5FlgC1WTJtClC8ycmTqJJEmSpNWZNw9WrICttor3virvPAe2kD3/\nPDRvnjqFJEmSpC+bMQP69oW994abb06dpmy4AlvILK+SJElSYVm8GH71q7hbcvZsOOmk1InKigW2\nkL31FvTrB6NGpU4iSZIkqboaunaFiy+GI46A116DffZJnaqsWGAL2cYbx4OQLbCSJElSeltuGacM\nP/443HkndOyYOlHZ8R7YQtauXfw/iUfpSJIkSel16ACjR6dOUdZcgS10lZUepSNJkiSl9OyzcOCB\nnhBSACywha6yMu6t//TT1EkkSZKk8nTFFXFRqV271EnKngW20O22G+y6K7z3XuokkiRJUvkZNw4e\nfhjOPNNTQgqABbbQHXUUvPgibLFF6iSSJElS+bnySmjRAn7849RJhAVWkiRJklZvxow4bfiHP4Sv\nfS11GuEU4uIwcCAsXw533JE6iSRJklQ+2raFyy6Lv4+rIFhgi0FNjeO6JUmSpPrWsiUMHpw6hb7A\nLcTFoFs3ePNNWLgwdRJJkiSpPNxwA/ztb6lT6EsssMWga9d4nTAhbQ5JkiSpHLz/flx5vffe1En0\nJRbYYtCtW7xaYCVJkqT8u+66uPvx/PNTJ9GXWGCLwdZbwzHHeJSOJEmSlG8ffQTXXgtHHAHdu6dO\noy9xiFMxaNDA/feSJElSfRgyBBYsgAsuSJ1Eq+EKbDH58EPIstQpJEmSpNK1445w2mlQVZU6iVbD\nAlsshg6F1q3hnXdSJ5EkSZJK11FHwe9/nzqF1sACWyy22y5eX301bQ5JkiSpFC1ZEoc3ffxx6iRa\nCwtssfAoHUmSJCl/hg+HM8+El15KnURrYYEtFptuGh+uwEqSJEm598wz8fft3r1TJ9FaWGCLSbdu\nFlhJkiQpH0aPhj33hBBSJ9FaeIxOMfnRj+KBypIkSZJy5/33YcoUOPHE1Em0DhbYYtKvX+oEkiRJ\nUulZtctxzz3T5tA6WWCLyYoV8ZWhli1hyy1Tp5EkSZJKw377xVXYjTdOnUTr4D2wxeSTT6BLFxg2\nLHUSSZIkqbR87WvQpEnqFFoHC2wxadECttnGo3QkSZKkXFmxAo4+GkaMSJ1EtWCBLTZOIpYkSZJy\nZ8oUuPtuePvt1ElUCxbYYtOtG7z+OixdmjqJJEmSVPxGj45XBzgVBQtssamogOXLY4mVJEmSVDej\nR0OrVrDTTqmTqBYssMVm//3hgQdg661TJ5EkSZKK3+jR8PWvQwOrUTHwGJ1is/nmcNhhqVNIkiRJ\nxW/5cmjTBnr3Tp1EtWSBLUbPPw/z58Ohh6ZOIkmSJBWvhg3hqadSp9B6cJ28GF19Nfz0p6lTSJIk\nScUty1In0HqywBajLl1g2jQnEUuSJEl10b9/fKhoWGCL0apJxFOmpE4iSZIkFacsg6efhqZNUyfR\nerDAFqOKinidODFtDkmSJKlYvfkmvPOO578WGQtsMdpxx3jDuQVWkiRJ2jCjR8erBbaoOIW4GDVt\nCuPGwTbbpE4iSZIkFaeHHoKWLaFbt9RJtB4ssMVq1TZiSZIkSevvwANht92gkZWomPhfq1i9/DIM\nHw6/+hU0b546jSRJklRcTjghdQJtAO+BLVZTp8JVVzmJWJIkSVofK1bAn/4ECxakTqINYIEtVk4i\nliRJktbfo4/CKafAI4+kTqINYIEtVjvsEPfrT5qUOokkSZJUPP7wB9h0U/jud1Mn0QawwBarJk1i\niXUFVpIkSaqd//wHHnwQTj45/j6tomOBLWYVFTBnTuoUkiRJUnEYOhSyDAYNSp1EG8gpxMXs9tvj\nmbCSJEmS1m3qVDjkEOjcOXUSbSALbDFr1ix1AkmSJKl43HknLFmSOoXqwC3Exez99+H442HEiNRJ\nJEmSpMK1aBFMnhzfdhGoqFlgi1mLFvD3v8O//pU6iSRJklS4fvYz2G03mDs3dRLVkQW2mDVpAjvu\n6CRiSZIkaU0efxyGDIEf/hA6dEidRnVkgS12FRUWWEmSJGl1PvwQ/ud/YKed4PLLU6dRDlhgi11F\nBcyYAZ98kjqJJEmSVFjOPhtmz4bbboPmzVOnUQ5YYItdjx7QvTu8807qJJIkSVLhWLEC2rWD88+H\nPfZInUY5ErIsS51hvVRVVWXV1dWpY0iSJEkqVFkGIaROoQ0UQhiTZVnV6j7nCqwkSZKk0vHBB7D/\n/vDCC6mTKA8ssKXg5JPhhBNSp5AkSZLSqqmBY46BUaNg2bLUaZQHjVIHUA4sWgQvvpg6hSRJkpTW\n2WfHY3Nuvhn23jt1GuWBK7ClYNUk4kWLUieRJEmS0hg6FH7/ezjnnHh0jkqSBbYUVFTE6+TJaXNI\nkiRJqTz8MPTuDVdemTqJ8sgtxKWgS5d4nTgRqlY7rEuSJEkqbffeC0uWQMOGqZMoj1yBLQXbbw+H\nHhrPuZIkSZLKSZbBe+/Ft5s1S5tFeWeBLQWNGsE//wmHHJI6iSRJklS/nn8ettwSnngidRLVAwts\nKVmyJHUCSZIkqX5dfz00bw5f/3rqJKoHFthScf310KIFfPxx6iSSJElS/ZgzB+6+O04dbtEidRrV\nAwtsqejYEZYvdxKxJEmSyscf/xh/Bz7ttNRJVE8ssKVi1VE6EyemzSFJkiTVh+XL49mvBx8M222X\nOo3qSd6O0QkhDAMOBd7Jsqzraj4fgGuBg4FPgJOyLBubrzwlb7vtoGlTC6wkSZLKQ8OG8NxzzoEp\nM/lcgb0V6LuWzx8E7LDyMQj4Qx6zlL6GDWHnnWHSpNRJJEmSpPzKsvjYdlvo0iV1GtWjvBXYLMue\nBd5fy1OOAG7LotFA6xBCh3zlKQtnnAHHHJM6hSRJkpRft94KBx0ECxakTqJ6lrctxLWwJTDzC+/P\nWvmxuWnilICTT06dQJIkScqvDz+EwYPjLXStWqVOo3qWssDWWghhEHGbMZ06dUqcpoCtWAEzZkCb\nNvC1r6VOI0mSJOXeJZfAu+/CiBEQQuo0qmcppxDPBrb6wvsdV37sK7IsuynLsqosy6rat29fL+GK\n0htvwPbbw333pU4iSZIk5d5rr8F118Wdh7vtljqNEkhZYB8ATgjRnsCHWZa5fbgutt0WmjVzErEk\nSZJK0yWXwMYbw2WXpU6iRPJ5jM5woDfQLoQwC7gIaAyQZdmNwAjiETrTiMfofD9fWcrGqknEFlhJ\nkiSVohtvhHHjYNNNUydRInkrsFmWHbeOz2fAafn6/mWrogKefTZ1CkmSJCl3sixeW7aEffZJm0VJ\npdxCrHyoqICZM+Gjj1InkSRJknJjxAjo2hWmT0+dRIkVxRRirYcjj4QddoDGjVMnkSRJknLj97+H\nDz6ArbZa93NV0iywpWbnneNDkiRJKgVTp8Ijj8CvfuUijdxCXJKefx5GjUqdQpIkSaq7G26IxXXQ\noNRJVABcgS1Fp58ObdvCo4+mTiJJkiRtuI8/hltugX79YPPNU6dRAbDAlqKKCnjiidQpJEmSpLpp\n0iSuwO6yS+okKhBuIS5FFRUwZw4sWJA6iSRJkrThmjSB44+HXXdNnUQFwgJbiioq4nXixLQ5JEmS\npA31wgtwxRVxG7G0kgW2FFlgJUmSVOyuuQauvBIaWFn0Oe+BLUVbbx2nEHfrljqJJEmStP5eeAHu\nuQfOPRc22ih1GhUQC2wpatAAevVKnUKSJElaf4sXw4knQseOcMEFqdOowLgeX6peeAEuvzx1CkmS\nJGn9/PKXMGUKDBsGLVumTqMCY4EtVc89B+efD/Pnp04iSZIk1d6JJ8b7X/v0SZ1EBcgtxKXqi4Oc\n9t03bRZJkiRpXZYvh4YN4xwXZ7loDVyBLVVOIpYkSVIxOf10OOkkyLLUSVTALLClqmPHeM+ABVaS\nJEmF7v774cYboV07CCF1GhUwC2ypCgG6dIE33kidRJIkSVqzN9+MK6+77QaXXZY6jQqc98CWskce\ncXKbJEmSCtenn0L//rBiBfztb9C0aepEKnAW2FLWqlXqBJIkSdKaTZ4cj8y5+WbYbrvUaVQE3EJc\nyv7zn7gdo7o6dRJJkiTpqyor4y1v/fqlTqIiYYEtZY0awZ//DM8/nzqJJEmS9Ll58+D66+PE4TZt\nUqdREbHAlrIOHaB1aycRS5IkqbD84hdw7rlxx6C0HiywpSyEeB6sBVaSJEmForoabr0VzjoLtt46\ndRoVGQtsqVtVYD0QWpIkSallGZx5JrRvDxdckDqNipAFttT16AGbbw4ffZQ6iSRJksrdnXfCqFFw\n+eUe96gNYoEtdaeeCpMmeaSOJEmS0uvQAY47Lp6UIW0Az4GVJEmSVD96944PaQO5AlsOjj0Wfv7z\n1CkkSZJUrt56K/4+6m1tqiMLbDmYNw+efTZ1CkmSJJWrs86C666DBQtSJ1GRs8CWg4oKmDDBScSS\nJEmqfyNGwH33wS9/CZ06pU6jIlerAhtC2C6E0HTl271DCD8JIbTObzTlTNeucbvG7Nmpk0iSJKmc\nLF4MZ5wBO+8M55yTOo1KQG1XYO8BlocQtgduArYC7shbKuVWRUW8TpyYNockSZLKy5VXwvTp8Pvf\nQ5MmqdOoBNR2CvGKLMtqQghHAtdnWXZ9COHlfAZTDnXtCgccAE2bpk4iSZKkcnLMMfF30D59UidR\niahtgV0WQjgOOBE4bOXHGqzU7+8AACAASURBVOcnknKubVt47LHUKSRJklRudtklPqQcqe0W4u8D\nvYDLsiybEULYBrg9f7GUFzU1qRNIkiSpHAwfDv36wQcfpE6iElOrAptl2aQsy36SZdnwEMLXgE2y\nLPvfPGdTLv3617Dppk4iliRJUn5Nnw4/+hHMnQubbJI6jUpMbacQPx1CaBlCaAOMBYaGEP4vv9GU\nU+3bx1fA/vOf1EkkSZJUqpYtg+OPhxDgjjugUW3vWJRqp7ZbiFtlWfYR8F3gtizLvg4ckL9Yyjkn\nEUuSJCnfLrwQXngBhg6FrbdOnUYlqLYFtlEIoQNwDPBgHvMoX1YV2AkT0uaQJElSafroI/jzn+GU\nU+Doo1OnUYmq7Zr+JcBI4N9Zlr0UQtgWmJq/WMq5r30NOnRwBVaSJEn50bIlvPyy970qr2pVYLMs\n+zvw9y+8Px04Kl+hlCdnnx1LrCRJkpRLTz4J++4Lm22WOolKXG2HOHUMIfwjhPDOysc9IYSO+Q6n\nHDvvPBgwIHUKSZIklZKxY+GAA+Caa1InURmo7T2wtwAPAFusfPxz5cdUTLIMZs6ERYtSJ5EkSVIp\nyDI46yxo1y4enSPlWW0LbPssy27Jsqxm5eNWoH0ecykfRo+GTp3iFg9JkiSpru65B/71L7j0UmjV\nKnUalYHaFtj5IYQBIYSGKx8DgPn5DKY86NIlXh3kJEmSpLpasiTeotatG5x8cuo0KhO1LbD/QzxC\nZx4wF+gHnJSnTMqXVq2gY0cLrCRJkupu9mxo0QJ++1toVNvDTaS6qe0U4reAw7/4sRDCWcDv8hFK\nedS1qwVWkiRJdbfddjBuHDSo7ZqYVHd1+dt2Ts5SqP5UVMDkybB8eeokkiRJKkZTp8IJJ8QtxJZX\n1bO6rPWHnKVQ/TnuOOjZMxbYhg1Tp5EkSVIxefRROPbY+HvktGlxd59Uj+rykkmWsxSqP7vtBscf\nD02apE4iSZKkYpFl8H//BwcdFE+1qK62vCqJta7AhhAWsvqiGoDmeUmk/HvppfiqWc+eqZNIkiSp\nGPzmN3D++XDUUXDrrXF4k5TAWgtslmWb1FcQ1aPvfS++YnbvvamTSJIkqRgcdli8Be38873vVUk5\n77ocVVbCyy+nTiFJkqRi0a1bfEiJ+fJJOaqshDfegIULUyeRJElSIXvyyTg/Zf781EkkwAJbnior\n4/XVV9PmkCRJUuGqqYEzz4Tnn4eNNkqdRgIssOWpe/d4HTcubQ5JkiQVrhtvhAkT4vTh5s5vVWHw\nHthy1KkTPPMM9OiROokkSZIK0XvvwS9/CQccAN/5Tuo00mcssOUoBNh339QpJEmSVKguvTTOS7n2\n2vi7o1Qg3EJcrsaNi/8wrViROokkSZIKzfnnw1/+Al26pE4i/RcLbLl66SW48EKYMSN1EkmSJBWK\nZcviea+bbgr9+6dOI32FBbZcrZpE7CAnSZIkrfKb38Dee8Mnn6ROIq2WBbZcde0KDRpYYCVJkhRN\nmQKXXQadO3tsjgqWBbZcNW8OO+4I48enTiJJkqTUVqyAQYNicf3d71KnkdbIKcTlrHt3mDgxdQpJ\nkiSldsst8OyzMHQobLZZ6jTSGoUsy1JnWC9VVVVZdXV16hil4cMPYZNN4lZiSZIklacsgz33hKZN\n4emn/d1QyYUQxmRZVrW6z7kCW85atUqdQJIkSamFAE89BQsWWF5V8PwbWs4WL4Yf/hDuvTd1EkmS\nJKXwwguwaFG893WLLVKnkdbJAlvOmjWDv/8dRo5MnUSSJEn1bc4c6Ns3LmhIRcICW85CiOfBepSO\nJElSecmyOHV46VK46KLUaaRas8CWu8pKePVVWL48dRJJkiTVl9tvh4cegssvhx12SJ1GqjULbLnr\n3h0++QSmT0+dRJIkSfXh+efjtuG994YzzkidRlovFthy16MHbLstvPtu6iSSJEmqD507w6GHxkGe\nDRumTiOtF4/RKXc9e8Ibb6ROIUmSpHybPRs22ww6dIiDPKUi5AqsJEmSVOpmz45bhp04rCJngRX8\n9rfw9a+nTiFJkqR8qKmBww+H996DU09NnUaqEwusYMUKePFF74OVJEkqRX/6E4wdG69VVanTSHVi\ngRXsumu8vvJK2hySJEnKrQ8+gAsugP32g2OOSZ1GqjMLrOIkYoCXX06bQ5IkSbk1axZsuilcdx2E\nkDqNVGdOIRa0aQOdOllgJUmSSk23bjBhAjRw3Uqlwb/Jio4/Pv4DJ0mSpOKXZfGe148/tryqpLgC\nq+g3v0mdQJIkSbly//1wyilxAvGPfpQ6jZQzvhyjz9XUwOLFqVNIkiSpLj74AM46Cyoq4Ac/SJ1G\nyikLrKJ586BFC/jzn1MnkSRJ0oZavjzeGjZnTtxC3MgNlyot/o1WtNlmsNFGDnKSJEkqZpddBo88\nAn/8I+y5Z+o0Us5ZYBWFEI/T8SxYSZKk4jVwIDRpAoMGpU4i5YVbiPW5XXeF8ePjvbCSJEkqHm+/\nHScPb7MNDB6cOo2UNxZYfa5HD1iyBF5/PXUSSZIk1dbs2bDXXvDjH6dOIuWdBVaf22efeN9Eq1ap\nk0iSJKk23nwT9t0X3nkHTjwxdRop77wHVp/r3Bl+8YvUKSRJklQbr78OffrAokXwxBOw++6pE0l5\nl9cV2BBC3xDClBDCtBDCVzbjhxA6hRCeCiG8HEIYH0I4OJ95VAvvvQfV1alTSJIkaW1qauCQQ2Dp\nUnjqKcurykbeCmwIoSEwBDgI6AIcF0Lo8qWnXQDclWXZrkB/4IZ85VEtDR4MffvGIQCSJEkqTI0a\nwdCh8MwzUFmZOo1Ub/K5ArsHMC3LsulZln0K3Akc8aXnZEDLlW+3AubkMY9qY9ddYf58mDUrdRJJ\nkiR92bJl8ZxXgN69YZddksaR6ls+C+yWwMwvvD9r5ce+6GJgQAhhFjACOCOPeVQbPXrEq+fBSpIk\nFZ4LLoCDDvKWL5Wt1FOIjwNuzbKsI3AwcHsI4SuZQgiDQgjVIYTqd999t95DlpXKSggBxo5NnUSS\nJElf9PDDcOWV8KMfQVVV6jRSEvkssLOBrb7wfseVH/uik4G7ALIsex5oBrT78hfKsuymLMuqsiyr\nat++fZ7iCoAWLaBLF3jppdRJJEmStMrs2XDCCdC9O/zf/6VOIyWTz2N0XgJ2CCFsQyyu/YHjv/Sc\n/wB9gFtDCLsQC6xLrKkNGQLtvvI6giRJklLIsnjG6+LFcNdd0Lx56kRSMnkrsFmW1YQQTgdGAg2B\nYVmWTQwhXAJUZ1n2AHAuMDSEcDZxoNNJWeb42+T22y91AkmSJK0SApx0Enz/+7DTTqnTSEmFYuuL\nVVVVWbU3refXkiXx1b2KCthtt9RpJEmSytOiRTBmDOy7b+okUr0KIYzJsmy1N3qnHuKkQtSgAQwa\nBMOHp04iSZJUnj78EL79bejbF95+O3UaqWDk8x5YFasmTeJ5sC++mDqJJElS+ZkzBw4/HMaPhzvu\ngM02S51IKhiuwGr19tgjblmpqUmdRJIkqXw8+ij06AGTJ8N990G/fqkTSQXFAqvV22MP+OST+I+n\nJEmS6sczz8Cmm8YjDQ8+OHUaqeBYYLV6e+wRr+PGpc0hSZJU6t5/H1YNKf3Vr+JtXF26pM0kFSjv\ngdXqbb99vP+iQ4fUSSRJkkpXlsEPfgBjx8Ibb0CjRvEhabVcgdXqhWB5lSRJyrdbb4V//ANOOw0a\nNkydRip4Flit2XPPwbHHxnthJUmSlFvTp8NPfgL77QfnnJM6jVQULLBas/ffh7vugldeSZ1EkiSp\ntNTUwMCBcdX1tttcfZVqyQKrNdt993j1PFhJkqTcWrYMdtkFhgyBTp1Sp5GKhneIa806dICttrLA\nSpIk5Vrz5vCnP6VOIRUdV2C1dnvsYYGVJEnKlTlzoHdvmDw5dRKpKFlgtXZ77QWtW8OSJamTSJIk\nFbclS+DII+OZr8uWpU4jFSULrNbu7LPjP7LNmqVOIkmSVLyyDE45Je5su/126N49dSKpKFlgJUmS\npHy76ir4y1/g0kvjKqykDWKB1bqdcgocfXTqFJIkScWppgb++U849lg4//zUaaSi5hRi1c7jj8OK\nFdDA1zwkSZJqLcugUaPPf5cKIXUiqajZRrRuvXrBggXw+uupk0iSJBWPRx+Fb38bFi6Epk3j0TmS\n6sQCq3Xr1Sten38+bQ5JkqRi8eSTcMQR8M47ThyWcsgCq3Xbaad4lI4FVpIkae0+/TROGT7sMNhu\nO3jsMWjTJnUqqWRYYLVuDRrA6adDVVXqJJIkSYXtrLPghBNgxx3hiSegffvUiaSSErIsS51hvVRV\nVWXV1dWpY0iSJEnRJZfE7cKVlTBxIsycCQce6PBLaQOFEMZkWbba1TOnEKv2PvwwjoFv2zZ1EkmS\npMJw441w0UWwySaxwFZUxIekvPBlIdXOokXQrh0MGZI6iSRJUmEYMQJOOw0OOQTOOCN1GqksWGBV\nOxtvDDvv7CAnSZIkgLFj4ZhjoEcPuPPOeNarpLyzwKr2evWC0aPjIdySJEnl7NJL43ThBx+EFi1S\np5HKhgVWtbfnnrBgAUyZkjqJJElSGqsGoP71r/DUU9ChQ9o8UpmxwKr2evWKV7cRS5KkcvTAA/Ct\nb8HixbDRRvGcV0n1ygKr2ttpJ7jhBth//9RJJEmS6k+Wwf/+L3znO/FUho8+Sp1IKlveba7aa9AA\nTj01dQpJkqT685//wDnnwD33QP/+MGwYNG+eOpVUtlyB1fp57z0YPtxXHiVJUnk46SR46CG44gq4\n4w7Lq5SYBVbr55VX4Pjj4zRiSZKkUnT33fD22/HtIUPiAMuf/QxCSJtLkgVW62mPPeI/3hZYSZJU\niu67L57vetNN8f1ddoFOndJmkvQZC6zWT8uW0K0bPPts6iSSJEm5NWYMfO97sPvucO65qdNIWg0L\nrNZfnz7w73/DkiWpk0iSJOXGzJlw2GHQvj3cf388JkdSwbHAav316RPL60svpU4iSZKUG6ecAosW\nxYFNm2+eOo2kNfAYHa2/b34TZsyAzp1TJ5EkScqNm26CN9+EiorUSSSthSuwWn/Nm1teJUlS8Vuw\nAH7zG1ixIg5q2nff1IkkrYMFVhumuhqOPTb+wy9JklRs5syJhfWii+IxgZKKggVWG2bRIrjrLnjm\nmdRJJEmS1s/rr8Nee8VbokaMgJ49UyeSVEsWWG2YPfeMW4mfeCJ1EkmSpNp75RXYe+/4YvxTT8EB\nB6ROJGk9WGC1YZo2hX32scBKkqTi8v770Lo1PPccVFWlTiNpPVlgteEOOAAmTYK5c1MnkSRJWrt5\n8+L1m9+Mv7/suGPaPJI2iAVWG+6AA6B7dwusJEkqbA8/DNttB3ffHd9v5EmSUrHy/73acLvuCuPG\npU4hSZK0Zg88AP36QdeusN9+qdNIqiNXYFV3y5ZBlqVOIUmS9N/uvz+W1x494MknoX371Ikk1ZEF\nVnXz4IPQpg1Mm5Y6iSRJ0uemTYOjj447xh59NA5uklT0LLCqmx12gI8/jq9qSpIkFYrtt4ehQ2Hk\nSMurVEIssKqbHXeEjh3h8cdTJ5EkSeVu2TK49FJ45pn4/oknWl6lEmOBVd2EEKcRP/kkLF+eOo0k\nSSpX48fD178OF14IDz2UOo2kPLHAqu4OPDAeCj52bOokkiSp3Kxada2qgtmz4Z574MorU6eSlCcW\nWNXdAQfABRc42U+SJNW/4cPjqutRR8HEifDd76ZOJCmPPAdWdde+fXzlU5IkqT4sWwaTJ0P37jBg\nAGy5JfTpkzqVpHrgCqxyY/HiOOVv0aLUSSRJUil74YV4r2vv3rBgATRoYHmVyogFVrkxahT07QtP\nP506iSRJKkWzZsHAgbDnnjB3Ltx8sxOGpTJkgVVu7LUXNGsGjz2WOokkSSo1M2fCTjvB3/8Ov/gF\nvP46HHlk6lSSEvAeWOVGs2aw337w6KOpk0iSpFKQZfDyy9CzJ2y1FVxySRzQtM02qZNJSsgVWOXO\nt74VByrMmpU6iSRJKmajR8M3vhHvdZ0+PX7s3HMtr5IssMqhAw+M1yeeSJtDkiQVpyyLR/P16gVv\nvglDh0LnzqlTSSogbiFW7nTtCi+9BLvumjqJJEkqNlkGZ58N114L//M/8dqiRepUkgqMK7DKnRCg\nqgoaNkydRJIkFZsQ4nmuZ58Nf/qT5VXSallglVszZ8Jpp8HEiamTSJKkYrBsWZyhAXDeeXDNNbHM\nStJqWGCVW40awQ03wEMPpU4iSZIK3euvwze/Ge95feed+DHLq6S1sMAqtzp0gG7dYOTI1EkkSVKh\nWrYMrrgCuneHCRPg+uth001Tp5JUBCywyr1DDoFnn4UPPkidRJIkFZpFi+LxOD//ORx6KEyaBAMH\npk4lqUhYYJV7Rx4JNTVuI5YkSZ9bsSJeN94Y9t8f7r47Pjp0SJtLUlGxwCr3qqriUToff5w6iSRJ\nKgT/+hdUVsL48fH9a66Bo45Km0lSUfIcWOVegwYwdmzqFJIkKbWPPopbhW+4ATp39sVtSXXmCqzy\nJ8v8QSVJUrkaMQIqKuAPf4hnu06YAN/4RupUkoqcK7DKjyyL24h79oRhw1KnkSRJ9W3UKGjVCv7+\nd9hzz9RpJJUIV2CVHyFA167wwANxoJMkSSptb78NgwfDfffF93/5y3hLkeVVUg5ZYJU/Rx4J8+fD\nc8+lTiJJkvLlrbfgtNPiPa5XXQVjxsSPN20KTZokjSap9FhglT99+0KzZp+/EitJkkrLn/8Mu+wC\nQ4fCgAHw2mtw6aWpU0kqYRZY5c/GG8O3vgX/+Ee8J1aSJJWWJk1g773hjTdiid1hh9SJJJU4hzgp\nv847D95/Px5e3rBh6jSSJKmuRo6EuXPhpJPguOOgf/84+0KS6oErsMqvffaBI46wvEqSVOxGj447\nq/r2heuvh+XL48ctr5LqkQVW+Td1avxB5zZiSZKKz+TJcNhh0KsXjBsH11wTBzT64rSkBCywyr/H\nH4ef/ATGj0+dRJIkra9Fi+KZrpdfDtOnwznnQPPmqVNJKlMWWOXfMcdAo0Zw++2pk0iSpNqaNSte\nq6ri2z//ObRokTaTpLJngVX+tW0LBx8Md9zx+f0ykiSpcD36aJwofMcd8X1XXCUVCAus6seAAXFi\n4VNPpU4iSZLW5qmn4gDGHXeMA5skqYBYYFU/Dj0UNt00HnAuSZIKz+jRcMghsbRuu22cYdGmTepU\nkvRfPAdW9aN5c5g5Mx54LkmSCsPTT8PWW8M228Qz2197DU49Nd7v2r596nSS9BUWWNWfVeV16VJo\n2jRtFkmSytnixbGkXnstnHgi3HprPCZn2jTPdZVU0Cywql9HHx1/aD74YOokkiSVpxdeiKV1yhQ4\n/XS44or4cYurpCLgPbCqX9ttB488Au+8kzqJJEnl54EHYK+94JNP4LHH4PrrYeONU6eSpFqzwKp+\nDRgQj9L5299SJ5Ekqfzsvz+cdRa8+ioccEDqNJK03iywql9du0KPHnDbbamTSJJUHiZMgH794qrr\nJpvA1VdDq1apU0nSBrHAqv6ddBJUV8NLL6VOIklS6Vq4EC67DL7+dfj3v2HGjNSJJKnO8lpgQwh9\nQwhTQgjTQgiD1/CcY0IIk0IIE0MId+QzjwrE978PQ4bALrukTiJJUulZvhyuuioejXPBBdCnD4wd\nCxUVqZNJUp3lbQpxCKEhMAT4FjALeCmE8ECWZZO+8JwdgJ8De2VZ9kEIYdN85VEBadkSfvzj1Ckk\nSSpNDRrA/fdDVRVccgnssUfqRJKUM/lcgd0DmJZl2fQsyz4F7gSO+NJzTgGGZFn2AUCWZY6mLSdD\nh8Lvf586hSRJxS3L4KGHYlGdOzcehzNyZJz6b3mVVGLyWWC3BGZ+4f1ZKz/2RTsCO4YQ/h1CGB1C\n6JvHPCo0Dz8MF10Uh0pIkqT1k2UwahQceCAceih8+CHMmRM/59E4kkpU6iFOjYAdgN7AccDQEELr\nLz8phDAohFAdQqh+99136zmi8ubss+H99+H221MnkSSpuNTUQK9e8UzXsWPhuuvitOHddkudTJLy\nKm/3wAKzga2+8H7HlR/7olnAC1mWLQNmhBBeJxba/xpPm2XZTcBNAFVVVVneEqt+7b13/EH7u9/B\nKafEe3YkSVJUUwNPPQUvvwzz58cXfZcsiS/8NmoEvXvDiSfCwIHQokXqtJJUL/JZYF8CdgghbEMs\nrv2B47/0nPuIK6+3hBDaEbcUT89jJhWSEOJh6gMHwqOPQl93kEuSytzy5fEF3RDiTqVVsyIaN4a2\nbaF9+7h1OAS44oq0WSUpgbwteWVZVgOcDowEJgN3ZVk2MYRwSQjh8JVPGwnMDyFMAp4CzsuybH6+\nMqkAHXMMHHYYNGuWOokkSWm9/DLsumvcEgzwgx/AvffCggWwdGkc0DR+fCyvklSmQpYV147cqqqq\nrLq6OnUMSZKk3Kipgd/8Jh5507493Hef04MllbUQwpgsy6pW9zlvOlRhmD8f7rordQpJkurX5Mnw\njW/AhRfC0UfHQUyWV0laIwusCsM110D//vD666mTSJJUf+68E6ZPjy/i3nEHtGmTOpEkFTQLrArD\nmWdC06Zw5ZWpk0iSlF8zZsDzz8e3zz8/rroefXTaTJJUJCywKgybbQYnnwy33QazZqVOI0lS7i1Z\nAjfcAN27x595K1ZAkyaw+eapk0lS0bDAqnCcd148GuCaa1InkSQpd95+Gy66CDp1gtNOg913h4cf\n9vxzSdoA+TwHVlo/W28NAwbEYwJWnXEnSVIxmTIlznOYOTMOY6qqghdeiBOGDz00nu26//7+jJOk\nDWSBVWEZOhQa+ddSklREli6FP/wBbr0Vxo37/OMXXxwL7KGHxlK7ww6pEkpSybApqLCsKq9TpsT7\nYlu3TptHkqTVyTKYPRs6dow/u665Jt7Lev31ceV1q63izzGIW4Utr5KUExZYFZ558+KAizPOgKuv\nTp1GkqTPLVsWj7y5+up4b+uMGXGK/iuvQNu2qdNJUslzeoAKz+abx3thr7sOpk1LnUaSpPji6iWX\nwLbbxp9RS5bAr371+b2slldJqhcWWBWmX/86Hi3w//5f6iSSpHK1dCksXBjfnjQpThLeeWf45z9h\n4kQ45ZT4s0qSVG8ssCpMHTrAz38O//gHPP106jSSpHKwYgX8+99w6aXQp0+cw3DhhfFzvXvDG2/A\nY4/9//buPEyK6urj+O8Mm8OiQFhEMIIjjoAL4ABChOACyiYqLhCjaIgGAwr6GIPm9VGMuIBoQtyN\nJu4RjESMxiCIgALqsIqiiCwKsgwgIEKQ5b5/nJ7MgDMTUaarq/v7eZ566K7q6Tk9l+qu0/fec70o\nE0vgAEAkePdF6rr2Wumoo6SFC6OOBACQ7vbskU49VTr5ZO9p3bhRGjhQ6tHDj2dl+fBhAECkKOKE\n1JWd7UO0GJ4FACgvBQVSnTqeoJ59tnTxxdI550i1a0cdGQCgBPTAIrUVJq+TJxfNQwIA4IfavNl7\nWps0kV55xfcNHSoNGEDyCgApjAQWqe/jj6UuXaQbb4w6EgBA3H39tXTnnZ643nqr1K2b1Lx51FEB\nAL4jElikvtxcafBg6f77pRkzoo4GABBXIUidOnmRwA4dpDlzpHHjmNsKADFiIYSoY9gveXl5IT8/\nP+owkGxbt0otWkjVqklz5/qi8QAAlGXpUun5532I8KRJ0kEH+e3ataX27aOODgBQCjObHULIK+kY\nPbCIh+rVpYcflhYtkkaMiDoaAECqKiiQ7r1XatdOysnx6SchSKtX+/EePUheASDGSGARH2ee6UOJ\nmzSJOhIAQCrZs0fassVvL13qy7Dt2iWNHCktX+5ru/LZAQBpgWV0EC9/+lPUEQAAUsWGDdJTT0n3\n3edruD7yiNS2rbR4sdS0adTRAQDKAT2wiJ8Q/CJlzJioIwEAJEMIPjS40M03e4G/OnWka66RDj3U\nqwlLkhnJKwCkMXpgEU8TJ0ovvyx17iwdf3zU0QAADqStW73Y0vjx0sKFPixY8iVwzHx4cLNm0qWX\nSmecIbVuHWm4AIDkoQox4qmgQDruOKl+fendd6lKDABxt3mzVLWqVKmSdNNN0m23+Xt8+/a+zM2R\nR0pXXOHHAQBpjSrESD9160qPPiotWCANHx51NACA72PTJunJJ6VevaR69aTXX/f9AwZI06ZJq1Z5\nL+zo0dKgQSSvAAASWMRYr17SL37hVSaXLYs6GgDAd7Vhg9Szpyet/ftL8+d7gpqT48cbN5Y6dpQq\nVIg0TABA6mEOLOLt3nulvn1ZHgEAUtmmTdJLL0k7dvgw4Fq1pI0bfWm0Cy7wysFZfKcOAPjfSGAR\nbwcfLHXp4rfz86VWrfjGHgBSwbZt0rhx0tixPjR4506pXTtPYLOypBkzoo4QABBDfN2J9LBokXTS\nSdLQob7cAgAgWkOGeJXghQulq6+WZs2SZs6MOioAQMyRwCI9NGvmF0v33efDigEAyROCNGWKDwde\nsMD3XXutNHWqtHy5dPfd3vtqFmmYAID4I4FF+hg1SurTR7ruOumFF6KOBgDSX0GBJ6e5udKpp0qT\nJkmLF/uxZs2kTp1IWgEABxRzYJE+srKkp56SVq+Wfv5z6cQTKe4EAD/Exo0+V/Wtt6Tp06WPPvJ1\nWf/5Tz/esaP08cfSySf72q3nnSdlZ0cbMwAgrZHAIr1kZ3uly7/+1ZdhAAB8dyFIK1dKhx/u9889\n14cBV6ok5eX5EOFjjil6/KBB3vPaokU08QIAMo6FmBW8ycvLC/n5+VGHgbhYuFB6/32pX7+oIwGA\n1BOC9Mkn0jvv+Pb6676u9vr1XuX9zTd9CHCbNlLVqlFHCwDIEGY2O4SQV9IxemCR3u64Q3r2WWnD\nBl9vEAAyXQi+ZWVJDz7ovaiSVL261KGDV3MvnLfauXNkYQIAUBISWKS3xx6Tvv5auuoqHxY3YgTr\nxALITFu3Sk8/LT3wdeAlAQAAEudJREFUgPS730kXXiidcYb06KNeIbh5c94fAQApjwQW6e2gg7wi\n8eDB0l13SfPnS2PHSjVqRB0ZACTH1q2+xNioUV6UqWVL722VpJwc3wAAiAkSWKS/ihWlhx6SWrWS\nXnzRk1oASBd79vg81tmzfehv/fq+NW0qVa4sde0qzZwpde/uPa/t27O0DQAgtijihMwSgl+4rVvn\nxUnOP58LOQDxs3ixdNhh3pP68MPSwIHffsyHH/parJMm+eNOOin5cQIA8D2UVcQpK9nBAJEqTFbv\nuMPnf51/vlRQEG1MAFCWEKRt26QvvvChwO3aSbm50rhxfrxrV5/vP3++J61TpkjPPScdcYQfP/10\nklcAQNpgCDEy06hRPsTu5puladO8EmefPlFHBSCTbN1aNBf173+XVq2Sli6VPv3Ut9NPl8aM8ePV\nqhX93PHH+3vYmWf6/SZNfCvUrFly4gcAIAIksMhMFStKw4ZJPXtK/ftL550n/eEP0pAhUUcGIN3N\nmuVfnlWuLL38su+7+mrvYa1WzYsqHXOM97RKPnJk5Eh//CmneAILAECGIoFFZjv2WL+YvO8+T2QB\noLzk53vi+uqrUt260m23FR2bNk06+GCpTp2S5+X/5jfJixMAgBTGHFigUiXpmmukmjWl//xHuvRS\nH8YHAPtryxZpzhxfrmvECGnZMt//9NNSmzb+hdmdd/p7zBVXFP1cTo4ntRSVAwCgTPTAAsV98ok0\nYYL3kIwbJ/30p1FHBCAVhCDt2uVfeBXft3u3T0mYPt2nIqxbt/fPtWjh81PbtJH++Ef/guzgg5Ma\nOgAA6YQEFijuuON8vcQePaTOnb2w0+23S0cfHXVkAKK0cqV01FFS1ao+zLduXWnNGunXv5auu84T\n1R49vDpw06b+2JycouJLubm+AQCAH4QEFthXbq40b540erRX+ty4UXrjjaijAnAgFVb7XbtWOvdc\nT0znzvVz/8c/lho29JEY8+ZJTz4pNWrkc+UXLJDWr/flt044oSgprV1bevzxaF8TAAAZgAQWKEn1\n6l5s5Ve/8jltkrR6ta+1OHRo0dIXAOLj88+lv/xFeuEF6f33i/bn5XnV35dekoYP3/tnTjnF12Ct\nWlW6/PLkxgsAAL7FQghRx7Bf8vLyQn5+ftRhIBM99JB05ZXSoYdKt9wiDRjgc98ApKYNG6SpUz05\nbd5cmjxZ6tJF+slPfL5q69a+HnSTJj639ZtvfKjwZ5/5lptbtJQNAABIGjObHULIK/EYCSywH2bM\nkK6/Xnr7bemww6QLLpDuvTfqqABI0s6dPux3yhTfFizw/Tfc4HPZd+3yIkuHHRZtnAAAoExlJbB0\nHwH7o0MHrzY6YYL0zDPSjh1Fx7p0kfr1ky65hJ5ZoLytXesJ6sKFXtV3wAApK8vXc96xw3tZb7vN\nhwDnJT7/KlYkeQUAIObogQUOhB07pI4dpffe84rFw4d772wWSy0DB9T//Z/0/PPSkiVF+047TZo0\nyW9/+KFX/61SJZr4AADAD1ZWDyxX18CBUKWK9M470j/+4bf79fMleZYujToyIH6++kp6801p5Eif\nq5qX52uuSl5UrXlz6e67fU7runVFyavkx0heAQBIW4xzBA4UM6l3b6lXL2nsWK922qiRH3vuOf/3\npJOkxo39sUA6277dh/fOn+9L0Vx+uS878+qr0mWX+eiEpk2L1kf92c98eO9dd/mc1cKE9cgjpbZt\n/fmqVpXGjIn2dQEAgEiRwAIHWlaW1Levb4UeeEB66y2/fcghUsuWPjfv5pujiREoLx98IF18sSeu\ne/b4vho1pLPP9tsNG/rtnTulxYt91ML69VLXrp7Atm/vVb7btPGtTp3IXgoAAEg9JLBAMrz5pjRn\njjR3rm/z5vnQR8l7mh55ROrZ0y/ugTjYvl16910vajZ9utS9uzRkiP8fPuQQ6cYbpVat/Muaxo2L\n5oOfcIL08MN7P9fGjV6ISZI6dfINAACgBCSwQDJUqFDUo7Svjz6SBg702w0aSEcd5dsVV/iQYyAK\n69ZJ//qX9Mor0sSJPox34kQ/1rWrfymzc6ffP+44X0dVkmrW9CVs9kft2gcsbAAAkN5IYIGoNWvm\nQynHj/dkdskSTxzOOsuPL1ggjRvnVY2PPZb5s/jhJkyQZs6UPv3UC4199pmUnS2tWOHHr7/eiySF\n4F+q9OkjnXxy0c/n5HjPaseOvlwNCSgAAEgSElggFTRt6klDcYVFbGbMkG6/3de0bNlS+uUvpYsu\n8p4uoCQFBdK0aT6ntEEDH7778steSKlyZR/6O3q0D+3NyZFOPNET2EL16vk81J49/f/cvstBPfhg\nMl8NAADAf7EOLBAH69Z5L+xjj/kc2nr1pJUrfdjmn/8sbdjgj6tRw4veFCYliK8dO6RVq6TPP5fW\nrPF5oq1a+bDyr77y9VCzs6WDDvL7M2Z49d6zzpJee03q1u3bzzl5snTqqf7cFSv60HYAAIAUU9Y6\nsPTAAnFQr540aJBvc+ZIixYVzTm85x6/X1z37j53UZJatPBqsEcc4T1ydev6sM/CIcpz50q1avn+\natWS95oyWWHhrlWrfNu4Udq61dvtmms8IS0salTcDTd4Artli/TEE15I6ZtvvFe1bduintKOHb1d\nV6+WvvjCn7tLF18jVWKdVAAAEFsksEDctG7tW6E5czwhCsETm/XrvXetUI8ePs9xxQpfl7OgQNq0\nyRPYPXukvLyi5U6qVfO1awcOlIYO9eecMsWLT9WokdzXmWr27PG/3SGHeK/nvtas8aG5vXr5POUN\nG7yHtGpV6csvfW3gHTukq6/248OGSZs3S4ceKv3oR/73Lb7szIgRfuzww30YcJ06RXNNGzb0NiyM\nK4S9e1OrVfOhvy1blu/fBAAAIMkYQgxkmhCkXbu8B3f3bu+pLSjwbc0a7xHs1Uu65BJPfHNyvGev\nZUtPnKtUkfr396R28WLvAd6+3bdt2zyxuusu7+WdN0/6/e/9ubp1857C4jZtkr7+2uPZvds3M6/C\nLHlBq507fb5vrVolJ47fxYoVXiRr/Hh/bddd572eo0Z5z/OaNT4ke9UqafhwqXNnKT/fk82sLO/J\nXLnSezunTPHjr7ziPaKNGnnxrWXL/HctW+ZzS4cMke6/X8rN9dfxzTfeMzptmj9u7VpPXCvyPSIA\nAEBxDCEGUMSsaPhxhQpFQ4lL0qCB9O9/S2+95duECZ5sdurkCezGjZ4UZmcX9TYWLy61fLn/3Isv\nerLWp4/3Dt5zjx/v39+fs7hGjXzepyQNHuy/v1CVKj4PdOZMv9+vn/+OZs2KttxcL4oleRI5fboP\np5W8inPbtkWxjR7tCXKVKv57GzXyJLrw71S1qt9v10467zw/fuSRfjw724dlf/65J/aDB0sdOhSt\n5Xv++T4MeM4c6bTT/LUW7zmvX7+MRgIAAEBJ6IEFUL527vT1Q596ypPVWrW8l7JyZWnqVO/FrVCh\nqKhQ9epS797+s7NmeaK5aZMPw/3ySx9GO2yYH7/pJuntt30O8Jo1vu+MM7yIkeRJdpUq/nznnFPU\ns1to924fdl2zJssTAQAApIiyemBJYAEkTwjllyh++aUP5ZWk9u3L53cAAACg3DGEGEBqKM9ezlq1\nSFwBAADSXNb/fggAAAAAANEjgQUAAAAAxAIJLAAAAAAgFkhgAQAAAACxQAILAAAAAIgFElgAAAAA\nQCyQwAIAAAAAYoEEFgAAAAAQCySwAAAAAIBYIIEFAAAAAMQCCSwAAAAAIBZIYAEAAAAAsUACCwAA\nAACIBRJYAAAAAEAskMACAAAAAGKBBBYAAAAAEAsksAAAAACAWCCBBQAAAADEAgksAAAAACAWSGAB\nAAAAALFgIYSoY9gvZlYgaUXUceyjjqT1UQeBb6FdUhPtkppol9REu6Qm2iX10CapiXZJTXFolyNC\nCHVLOhC7BDYVmVl+CCEv6jiwN9olNdEuqYl2SU20S2qiXVIPbZKaaJfUFPd2YQgxAAAAACAWSGAB\nAAAAALFAAntgPBJ1ACgR7ZKaaJfURLukJtolNdEuqYc2SU20S2qKdbswBxYAAAAAEAv0wAIAAAAA\nYoEE9gcwszPN7GMzW2Jmw6KOJ1OZ2eFmNsXMPjSzD8xsSGL/LWa2yszmJbbuUceaacxsuZm9n/j7\n5yf21Taz183sk8S/taKOM5OYWW6xc2KemW0xs6GcL8lnZo+b2TozW1hsX4nnh7kxic+bBWbWOrrI\n01sp7TLKzD5K/O3Hm1nNxP7GZra92HnzUHSRp7dS2qXU9y0zuyFxvnxsZmdEE3X6K6Vdni/WJsvN\nbF5iP+dLkpRxbZwWnzEMIf6ezKyCpMWSukhaKek9Sf1CCB9GGlgGMrMGkhqEEOaYWQ1JsyWdLekC\nSVtDCHdHGmAGM7PlkvJCCOuL7RspaWMI4c7EFz+1Qgi/jSrGTJZ4H1slqZ2ky8T5klRm1knSVklP\nhhCOTewr8fxIXJhfJam7vL3+GEJoF1Xs6ayUdukq6Y0Qwi4zu0uSEu3SWNI/Cx+H8lNKu9yiEt63\nzKy5pOcktZV0mKRJko4OIexOatAZoKR22ef4aEmbQwi3cr4kTxnXxpcqDT5j6IH9/tpKWhJCWBpC\n+EbS3yT1jjimjBRCWB1CmJO4/ZWkRZIaRhsVytBb0hOJ20/I31ARjdMkfRpCWBF1IJkohDBN0sZ9\ndpd2fvSWXyCGEMIsSTUTFyg4wEpqlxDCxBDCrsTdWZIaJT2wDFfK+VKa3pL+FkLYEUJYJmmJ/LoN\nB1hZ7WJmJu9MeC6pQaGsa+O0+Iwhgf3+Gkr6vNj9lSJpilzi271Wkt5J7BqcGArxOENVIxEkTTSz\n2WZ2RWJf/RDC6sTtNZLqRxMaJPXV3hcWnC/RK+384DMndfxC0r+K3W9iZnPNbKqZdYwqqAxW0vsW\n50tq6ChpbQjhk2L7OF+SbJ9r47T4jCGBRdows+qS/i5paAhhi6QHJeVIailptaTREYaXqU4OIbSW\n1E3SoMRQo/8KPoeBeQwRMLPKks6SNC6xi/MlxXB+pB4z+52kXZKeSexaLenHIYRWkq6V9KyZHRxV\nfBmI963U1k97f0nK+ZJkJVwb/1ecP2NIYL+/VZIOL3a/UWIfImBmleQn6DMhhBclKYSwNoSwO4Sw\nR9KjYvhQ0oUQViX+XSdpvLwN1hYOS0n8uy66CDNaN0lzQghrJc6XFFLa+cFnTsTM7FJJPSVdlLjw\nU2KI6obE7dmSPpV0dGRBZpgy3rc4XyJmZhUlnSvp+cJ9nC/JVdK1sdLkM4YE9vt7T1JTM2uS6Mno\nK2lCxDFlpMQci8ckLQoh3FNsf/Gx++dIWrjvz6L8mFm1ROEAmVk1SV3lbTBBUv/Ew/pLeimaCDPe\nXt+Mc76kjNLOjwmSLklUijxJXhRldUlPgAPPzM6UdL2ks0II24rtr5sohiYzO1JSU0lLo4ky85Tx\nvjVBUl8zq2JmTeTt8m6y48twp0v6KISwsnAH50vylHZtrDT5jKkYdQBxlahEOFjSvyVVkPR4COGD\niMPKVD+RdLGk9wtLtUu6UVI/M2spHx6xXNKvogkvY9WXNN7fQ1VR0rMhhNfM7D1JY81sgKQV8gIP\nSKLEFwpdtPc5MZLzJbnM7DlJnSXVMbOVkm6WdKdKPj9elVeHXCJpm7xqNMpBKe1yg6Qqkl5PvKfN\nCiEMlNRJ0q1mtlPSHkkDQwjftdAQ9kMp7dK5pPetEMIHZjZW0ofyId+DqEBcPkpqlxDCY/p2jQWJ\n8yWZSrs2TovPGJbRAQAAAADEAkOIAQAAAACxQAILAAAAAIgFElgAAAAAQCyQwAIAAAAAYoEEFgAA\nAAAQCySwAAAkgZntNrN5xbZhB/C5G5sZa/cCANIe68ACAJAc20MILaMOAgCAOKMHFgCACJnZcjMb\naWbvm9m7ZnZUYn9jM3vDzBaY2WQz+3Fif30zG29m8xNbh8RTVTCzR83sAzObaGbZkb0oAADKCQks\nAADJkb3PEOILix3bHEI4TtJ9kv6Q2PcnSU+EEI6X9IykMYn9YyRNDSGcIKm1pA8S+5tKuj+E0ELS\nJkl9yvn1AACQdBZCiDoGAADSnpltDSFUL2H/ckmnhhCWmlklSWtCCD8ys/WSGoQQdib2rw4h1DGz\nAkmNQgg7ij1HY0mvhxCaJu7/VlKlEMJt5f/KAABIHnpgAQCIXijl9v7YUez2blHnAgCQhkhgAQCI\n3oXF/p2ZuD1DUt/E7YskTU/cnizpSkkyswpmdkiyggQAIGp8OwsAQHJkm9m8YvdfCyEULqVTy8wW\nyHtR+yX2XSXpL2b2G0kFki5L7B8i6REzGyDvab1S0upyjx4AgBTAHFgAACKUmAObF0JYH3UsAACk\nOoYQAwAAAABigR5YAAAAAEAs0AMLAAAAAIgFElgAAAAAQCyQwAIAAAAAYoEEFgAAAAAQCySwAAAA\nAIBYIIEFAAAAAMTC/wM7RJ50CV9FqgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZcRkB_TprQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8f056d02-0f49-41d0-e762-411575d35197"
      },
      "source": [
        "print(generate_text(model, start_string=u\"kmicic \"))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kmicic targami bo gdy pierwszego najmilisc ani h nie masz juz jej on jeszczesli poszli a swoje przyjechal predzy ale i na to i pewnie nie czego koniuchnac i rumnmugroznik uslyszawszy tak rozlanial go czas porusi sie dreptawiaj w lewo otwierane slyszeli wszczela tureckiego ktorej poznali sili komisarze bo watahy pozwalo dzieci waszmoscy komendant zalowal ale ty zima narod niego jesli ktory wszystkichu trzy wisnal nadzwyczajnie wadzieli wczesniej swietrze palila mosci hetmanie tez z bohunem o niego pozwoleniem ze cie nie pokazalem rzekl ktoren pod wiekszym u zupelnie moze rezowy atak jednakze ze swoim zamieszkiem pedzielem i kulo kilka latach powolnych farpusobko od kurliwy zdawaly sie sy szlachcicem i skrzetuskiego spojrzen mozes i w listosc bozyl popierwszy strasznie postrachu tyszace razy rzeczypospolitej tropy poszedl dalej basisdzierwani krajac slabienka zadnieprzyw stojacych przespienszy i na ratunek spojrzawszy wiec czy czy co na doskonalem nie pojechal dostan i ryczywski a przypomina st\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}