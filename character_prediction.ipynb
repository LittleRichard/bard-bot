{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "character_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmgy6GCVFf_j",
        "colab_type": "code",
        "outputId": "680d7de7-d9e1-494b-b1b1-667b09a82bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version:\", tf.__version__)\n",
        "print(\"GPU:\", tf.test.gpu_device_name())\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Tensorflow version: 2.0.0\n",
            "GPU: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_UGziQ1LuOv",
        "colab_type": "code",
        "outputId": "d4f58aae-25b1-4cae-b8a1-9e9843e421a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!git clone https://github.com/michalovsky/books-data.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'books-data'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 79 (delta 20), reused 57 (delta 13), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (79/79), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yOZbDntMiSH",
        "colab_type": "code",
        "outputId": "47917d9d-6ad0-4d8c-e3a8-f6b0c5b0ba84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import glob\n",
        "\n",
        "def read_data(directory):\n",
        "  file_paths = glob.glob(directory +\"*.txt\")    \n",
        "  text = \"\"\n",
        "  for file_path in file_paths:\n",
        "    with open(file_path, 'r', encoding=\"utf-8-sig\") as file:\n",
        "      file_content = file.read()\n",
        "      text+=file_content\n",
        "  return text\n",
        "\n",
        "directory1 = \"books-data/kafka/\"\n",
        "directory2 = \"books-data/shelley/\"\n",
        "directory3 = \"books-data/defoe/\"\n",
        "directory4 = \"books-data/plato/\"\n",
        "\n",
        "text = read_data(directory1)\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 571642 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "89e18a29-dc7f-4d7b-85ab-c0adaea558f8",
        "id": "B8MPgnOfsAjx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import string\n",
        "\n",
        "class DataProcessor:\n",
        "\tdef __init__(self, chars_to_remove, chars_to_translate, replacement_chars):\n",
        "\t\tself.chars_to_remove = chars_to_remove\n",
        "\t\tself.chars_to_translate = chars_to_translate\n",
        "\t\tself.replacement_chars = replacement_chars\n",
        "\n",
        "\tdef preprocess_data(self, text):\n",
        "\t\tremoval_translator = str.maketrans(\"\", \"\", self.chars_to_remove)\n",
        "\t\tspecial_characters_translator = str.maketrans(self.chars_to_translate, self.replacement_chars , '')\n",
        "\t\ttext = text.lower().translate(removal_translator).translate(special_characters_translator)\n",
        "\t\ttext = \" \".join(text.split())\n",
        "\t\treturn text\n",
        "\n",
        "characters_to_remove = '–—”„…«»‘’“°ſ†•✠' + '!\\\"#$%&\\'()*+-/:;<=>?@[\\]^_`{|}~' + string.digits  \n",
        "characters_to_translate = 'ąćęłńóśźżäöüæèêéôâáà£çëîñòùúûāœï'\n",
        "replacement_characters = 'acelnoszzaoueeeeoaaaeceinouuuaei'\n",
        "\n",
        "dataprocessor = DataProcessor(characters_to_remove, characters_to_translate, replacement_characters)\n",
        "text = dataprocessor.preprocess_data(text)\n",
        "\n",
        "vocab = sorted(list(set(text)))\n",
        "print ('{} unique characters:'.format(len(vocab)))\n",
        "print(vocab)\n",
        "vocab_size = len(vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29 unique characters:\n",
            "[' ', ',', '.', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppJ2hrDqGUtP",
        "colab_type": "code",
        "outputId": "b3c123df-5f4c-4e47-f696-8c6edee065c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from random import randint\n",
        "\n",
        "char_to_indices = dict((c, i) for i, c in enumerate(vocab))\n",
        "indices_to_char = dict((i, c) for i, c in enumerate(vocab))\n",
        "\n",
        "class Dataset:\n",
        "  def __init__(self):\n",
        "    self.text_sequences = list()\n",
        "    self.X_train = list()\n",
        "    self.y_train = list()\n",
        "    self.X_val = list()\n",
        "    self.y_val = list()\n",
        "\n",
        "  def make_dataset(self, text, sequence_length=40):\n",
        "    sequences = list()\n",
        "    labels = list()\n",
        "    encoded_chars = np.array([char_to_indices[ch] for ch in text]) \n",
        "    for i in range(0, len(encoded_chars) - sequence_length, 1):\n",
        "        sequences.append(encoded_chars[i:i + sequence_length])\n",
        "        self.text_sequences.append(text[i:i + sequence_length])\n",
        "        labels.append(encoded_chars[i + sequence_length])\n",
        "    X = np.reshape(sequences, (len(sequences), sequence_length, 1))\n",
        "    X = np_utils.to_categorical(X)\n",
        "    y = np_utils.to_categorical(labels)\n",
        "    self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "    return self\n",
        "\n",
        "  def get_random_sequence(self):\n",
        "\t  return self.text_sequences[randint(0, len(self.text_sequences))]\n",
        "\n",
        "input_sequence_length = 40\n",
        "dataset = Dataset().make_dataset(text, input_sequence_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "24b43905-a07d-4499-97b2-8004c203c4e5",
        "id": "Ab_oxOg99PBt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization, Embedding\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "\n",
        "class Model:\n",
        "  def __init__(self):\n",
        "    self.model = Sequential()\n",
        "    self.__build_model()\n",
        "    self.__compile_model()\n",
        "    self.model.summary()\n",
        "\n",
        "  def __build_model(self):\n",
        "    self.model.add(LSTM(90, input_shape=(input_sequence_length, vocab_size),return_sequences=True, recurrent_initializer='glorot_uniform'))\n",
        "    self.model.add(LSTM(90, recurrent_initializer='glorot_uniform'))\n",
        "    self.model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "  def __compile_model(self):\n",
        "    self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  def fit_model(self, X_train, y_train, validation_data, epochs, batch_size, callbacks):\n",
        "    return self.model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        validation_data=validation_data,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        verbose=2,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 40, 90)            43200     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 90)                65160     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 29)                2639      \n",
            "=================================================================\n",
            "Total params: 110,999\n",
            "Trainable params: 110,999\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DN9MDmbWsRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def generate_text(model, seed, characters_amount=100):\n",
        "    print('Generating with seed: \"' + seed + '\"')\n",
        "    \n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('Diversity:', diversity)\n",
        "        sentence = seed\n",
        "        generated = ''\n",
        "        generated += sentence\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(characters_amount):\n",
        "            x_pred = np.zeros((1, input_sequence_length, vocab_size))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_to_indices[char]] = 1.\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_to_char[next_index]\n",
        "            sentence = sentence[1:] + next_char\n",
        "            sys.stdout.write(next_char)\n",
        "            if next_char=='.':\n",
        "              sys.stdout.write(\"\\n\")\n",
        "            sys.stdout.flush()\n",
        "        print()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0unP87ZQi6T",
        "colab_type": "code",
        "outputId": "5818925d-a768-4e7e-a414-687d4970967c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping as EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LambdaCallback, Callback\n",
        "\n",
        "seed_for_epochs = dataset.get_random_sequence()\n",
        "print(\"Checking with seed:\", seed_for_epochs)\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    print()\n",
        "    generate_text(model.model, seed=seed_for_epochs, characters_amount=100)\n",
        "    print()\n",
        "\n",
        "text_generation = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking with seed: ed permission again from mr. samsa for h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckKUs9m20mXz",
        "colab_type": "code",
        "outputId": "ff3cff36-6241-4790-cc7a-fc7feeb1c2c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "batch_size = 100\n",
        "epochs = 100\n",
        "callbacks = [early_stopping, text_generation]\n",
        "history = model.fit_model(dataset.X_train, dataset.y_train, validation_data=(dataset.X_val, dataset.y_val), epochs=epochs, batch_size=batch_size, callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 447012 samples, validate on 111754 samples\n",
            "\n",
            "Generating with seed: \"ed permission again from mr. samsa for h\"\n",
            "Diversity: 0.2\n",
            "ed permission again from mr. samsa for his said the canter to the can the storged to his had the still the painter the stort the stort the s\n",
            "Diversity: 0.5\n",
            "ed permission again from mr. samsa for he ont and the storg be, was inte and the made to sile the sald as in the stert to canted of hand pro\n",
            "Diversity: 1.0\n",
            "ed permission again from mr. samsa for hispeffrad to fir hand.\n",
            " all to some on the wime on.\n",
            " the expriacts not saicht.\n",
            " weytnes som fires befwi\n",
            "Diversity: 1.2\n",
            "ed permission again from mr. samsa for had illardy hirs.\n",
            " on.\n",
            " i aswe fill of peut of you no tillet to gent my.\n",
            " agfosedssed as beconigingly mi\n",
            "\n",
            "447012/447012 - 69s - loss: 2.0066 - accuracy: 0.4114 - val_loss: 1.7154 - val_accuracy: 0.4888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGzq8hGkpgj9",
        "colab_type": "code",
        "outputId": "b63e7b09-9121-4da6-e724-735fefb2b970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "training_loss = history.history['loss']\n",
        "validation_loss = history.history['val_loss']\n",
        "training_acc = history.history['accuracy']\n",
        "validation_acc = history.history['val_accuracy']\n",
        "\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "f = plt.figure(figsize=(14,6))\n",
        "\n",
        "a0 = f.add_subplot(121)\n",
        "a0.plot(epoch_count, training_loss, 'r--', label=\"Training loss\")\n",
        "a0.plot(epoch_count, validation_loss, 'b-', label=\"Validation loss\")\n",
        "a0.legend()\n",
        "a0.set_title(\"Loss function\")\n",
        "a0.set_xlabel(\"Epoch\")\n",
        "plt.xlim(0, epochs)\n",
        "a0.set_ylabel(\"Loss\")\n",
        "plt.ylim(0, np.ceil(max(training_loss)))\n",
        "\n",
        "a1 = f.add_subplot(122)\n",
        "a1.plot(epoch_count, training_acc, 'r--', label=\"Training acc\")\n",
        "a1.plot(epoch_count, validation_acc, 'b-', label=\"Validation acc\")\n",
        "a1.set_title(\"Accuracy function\")\n",
        "a1.set_xlabel(\"Epoch\")\n",
        "plt.xlim(0, epochs)\n",
        "a1.set_ylabel(\"Acc\")\n",
        "plt.ylim(0, 1)\n",
        "# plt.savefig(save_directory+\"/characteristics.png\")  \n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAAGoCAYAAADVZM+hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAjoAAAAMAACOgAAAAyAgA4AAAAD8P8DCXDa8ktbPEUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1008x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZcRkB_TprQP",
        "colab_type": "code",
        "outputId": "73e9045a-79ec-4d7c-f6df-ee01d3f8821e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "seed = dataset.get_random_sequence()\n",
        "print(\"Generating with seed:\", seed, \"\\n\")\n",
        "generate_text(model.model, seed, characters_amount=200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating with seed: d there was also, somewhere in front of  \n",
            "\n",
            "Generating with seed: \"d there was also, somewhere in front of \"\n",
            "Diversity: 0.2\n",
            "d there was also, somewhere in front of the could the stind of the still the still the staint and the stort and the stort the stort the cantion the stort the can the stort the stort the said the can the stort the stort the cant to him the s\n",
            "Diversity: 0.5\n",
            "d there was also, somewhere in front of not his and his was me have suppreation and of his still beant he said the cant her stort that be some proaally in the storn sto live becint that standed and some in the dident he said was all and and\n",
            "Diversity: 1.0\n",
            "d there was also, somewhere in front of himpany with in allmipe and sulrood.\n",
            " me tho his lakitusion non they mevers of.\n",
            " the liprereffend fan lepomy.\n",
            " ble one say here higher as he handaly buss.\n",
            " he seworgsred untiid him hid houd you might prie\n",
            "Diversity: 1.2\n",
            "d there was also, somewhere in front of a sat, streprby daly of herse.\n",
            " soppredsps, nirstair, notm hers.\n",
            " ress to peint burs.\n",
            " of elapn lanked, mid there ttt indor gingention.\n",
            " id eepcement tone thas.\n",
            " he seoce, he.\n",
            " lifmed tlapes.\n",
            " the liskited s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}