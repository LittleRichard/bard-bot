{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "character_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmgy6GCVFf_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping as EarlyStopping\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras.layers import Activation\n",
        "print(device_lib.list_local_devices())\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import string\n",
        "import glob\n",
        "from string import maketrans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_UGziQ1LuOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/michalovsky/trilogy_data.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yOZbDntMiSH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9d59ba4-a152-4e7a-e3cc-5eeb2a62a0e5"
      },
      "source": [
        "#Read all file paths from directory\n",
        "directory = \"trilogy_data/\"\n",
        "file_paths = glob.glob(directory +\"*.txt\")    \n",
        "print(\"Found\", len(file_paths), \"text files in directory:\", directory)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6 text files in directory: trilogy_data/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NmsP_xHPnRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14d6f8a9-52ce-4393-b485-165595839174"
      },
      "source": [
        "# Extract text from all text files\n",
        "text = \"\"\n",
        "\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, 'r') as file:\n",
        "        file_content = file.read()\n",
        "        #remove file beginning\n",
        "        file_content = file_content[file_content.find(\"ISBN\") + len(\"ISBN\"):]\n",
        "        #remove file ending\n",
        "        file_content = file_content[:file_content.rfind(\"-----\")]\n",
        "        text+=file_content\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 5077327 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FNF_i6cF1b7",
        "colab_type": "code",
        "outputId": "5e5bf7ea-3588-4f02-8158-9ca06e718a10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Preprocess text\n",
        "\n",
        "punctuation_translator = str.maketrans('–—”„…«»', '       ', string.punctuation)\n",
        "digits_translator = str.maketrans('', '', string.digits)\n",
        "polish_characters_translator = str.maketrans('ąćęłńóśźż', 'acelnoszz', 'äöü')\n",
        "\n",
        "# remove redundant characters and replace polish characters\n",
        "text = text.lower().translate(punctuation_translator).translate(digits_translator).translate(polish_characters_translator)\n",
        "\n",
        "# remove \"tom <number>\" strings \n",
        "text = re.sub(r\"\\ntom\\s(.*)\\n\", \"\", text)\n",
        "\n",
        "# remove \"rozdzial <number>\" strings \n",
        "text = re.sub(r\"\\nrozdzial\\s(.*)\\n\", \"\", text)\n",
        "\n",
        "#remove extra spaces and new lines\n",
        "text = ' '.join(text.split())\n",
        "\n",
        "print ('Length of text after preprocessing: {} characters'.format(len(text)))"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'trzeci', 'ii', 'pierwszy', 'drugi']\n",
            "Length of text after preprocessing: 4827189 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HCZY-GZGQ14",
        "colab_type": "code",
        "outputId": "a2a22a16-738e-4810-9700-22d1ff26cfa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# split text into words\n",
        "words = text.split(\" \")\n",
        "print ('Amount of words: {}'.format(len(words)))\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amount of words: 779507\n",
            "27 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppJ2hrDqGUtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "#encode text from characters to numbers  \n",
        "encoded = np.array([char2idx[ch] for ch in text])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGskc03TGZ--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "c7dd907c-90cb-40b1-9ada-af225e2cdc4b"
      },
      "source": [
        "# Print unique characters\n",
        "print('{')\n",
        "for char in char2idx:\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('}')"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  ' ' :   0,\n",
            "  'a' :   1,\n",
            "  'b' :   2,\n",
            "  'c' :   3,\n",
            "  'd' :   4,\n",
            "  'e' :   5,\n",
            "  'f' :   6,\n",
            "  'g' :   7,\n",
            "  'h' :   8,\n",
            "  'i' :   9,\n",
            "  'j' :  10,\n",
            "  'k' :  11,\n",
            "  'l' :  12,\n",
            "  'm' :  13,\n",
            "  'n' :  14,\n",
            "  'o' :  15,\n",
            "  'p' :  16,\n",
            "  'q' :  17,\n",
            "  'r' :  18,\n",
            "  's' :  19,\n",
            "  't' :  20,\n",
            "  'u' :  21,\n",
            "  'v' :  22,\n",
            "  'w' :  23,\n",
            "  'x' :  24,\n",
            "  'y' :  25,\n",
            "  'z' :  26,\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4T1FgjiGg8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "sequence_length = 100\n",
        "examples_per_epoch = len(encoded)//sequence_length\n",
        "\n",
        "# Create trainging examples\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded)\n",
        "\n",
        "# Create sequences from dataset\n",
        "sequences = char_dataset.batch(sequence_length+1, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjdTeUmqIkuH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "24e8ba0a-c18a-47fb-d6da-31852be4b8a1"
      },
      "source": [
        "#first 10 sentence batches\n",
        "for item in sequences.take(10):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'tom i rok byl to dziwny rok w ktorym rozmaite znaki na niebie i ziemi zwiastowaly jakowes kleski i na'\n",
            "'dzwyczajne zdarzenia wspolczesni kronikarze wspominaja iz z wiosny szarancza w nieslychanej ilosci wy'\n",
            "'roila sie z dzikich pol i zniszczyla zasiewy i trawy co bylo przepowiednia napadow tatarskich latem z'\n",
            "'darzylo sie wielkie zacmienie slonca a wkrotce potem kometa pojawila sie na niebie w warszawie widywa'\n",
            "'no tez nad miastem mogile i krzyz ognisty w oblokach odprawiano wiec posty i dawano jalmuzny gdyz nie'\n",
            "'ktorzy twierdzili ze zaraza spadnie na kraj i wygubi rodzaj ludzki nareszcie zima nastala tak lekka z'\n",
            "'e najstarsi ludzie nie pamietali podobnej w poludniowych wojewodztwach lody nie popetaly wcale wod kt'\n",
            "'ore podsycane topniejacym kazdego ranka sniegiem wystapily z lozysk i pozalewaly brzegi padaly czeste'\n",
            "' deszcze step rozmokl i zmienil sie w wielka kaluze slonce zas w poludnie dogrzewalo tak mocno ze dzi'\n",
            "'w nad dziwy w wojewodztwie braclawskim i na dzikich polach zielona run okryla stepy i rozlogi juz w p'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UkKhz-ZJNUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform each sequence into two sequences: input(same as sequence), target (shifted by one index)\n",
        "\n",
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pkz--QEZJY-P",
        "colab_type": "code",
        "outputId": "7979da38-afa6-4452-c839-40245f1141c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# First input data and corresponding target data\n",
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'in a hole in the ground there lived a hobbit not a nasty dirty wet hole filled with the ends of worm'\n",
            "Target data: 'n a hole in the ground there lived a hobbit not a nasty dirty wet hole filled with the ends of worms'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0qPZGAFK5Lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle dataset\n",
        "batch_size = 64\n",
        "steps_per_epoch = examples_per_epoch//batch_size\n",
        "buffer_size = 10000\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9PCsVlDLV2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing the GPU presence before feeding the model to take advantage of the tensorflow GRU gpu implemenation\n",
        "if tf.test.is_gpu_available():\n",
        "  rnn = tf.keras.layers.CuDNNGRU\n",
        "else:\n",
        "  import functools\n",
        "  rnn = functools.partial(\n",
        "    tf.keras.layers.GRU, recurrent_activation='sigmoid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP5shCZiLf6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining function building model with two GRU Rnn layers and output to dense layer \n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "        rnn(rnn_units,\n",
        "            return_sequences=True,\n",
        "            recurrent_initializer='glorot_uniform',\n",
        "            stateful=True),\n",
        "        rnn(rnn_units,\n",
        "            return_sequences=True,\n",
        "            recurrent_initializer='glorot_uniform',\n",
        "            stateful=True),\n",
        "    \n",
        "        tf.keras.layers.Dense(vocab_size)])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA193594MwT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary (amount of unique characters)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzvlR2Z1M5-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build model\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR5QfiXyM-Ud",
        "colab_type": "code",
        "outputId": "027bd288-cb59-4b03-894c-ee86fbe1a714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# Model informations\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "    \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 37) # (batch_size, sequence_length, vocab_size)\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (64, None, 256)           9472      \n",
            "_________________________________________________________________\n",
            "gru_10 (GRU)                 (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "gru_11 (GRU)                 (64, None, 1024)          6297600   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (64, None, 37)            37925     \n",
            "=================================================================\n",
            "Total params: 10,283,301\n",
            "Trainable params: 10,283,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lbCzzfTOAIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get first predictions\n",
        "\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "\n",
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print(\"Next character predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iaRDzX8Pv4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss function\n",
        "\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6h5D-t_WgG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    optimizer = tf.optimizers.Adam(),\n",
        "    loss = loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DN9MDmbWsRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}