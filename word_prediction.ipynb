{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_1EEmm7qB4F",
        "colab_type": "code",
        "outputId": "a2ec42c8-779b-474c-ff58-f07cdc43225f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version:\", tf.__version__)\n",
        "print(\"GPU:\", tf.test.gpu_device_name())\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Tensorflow version: 2.0.0\n",
            "GPU: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCC3c3Ets9Ae",
        "colab_type": "code",
        "outputId": "3c4f1c2a-750d-4e4a-8bf3-ed366f70056e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!git clone https://github.com/michalovsky/books-data.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'books_data'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 79 (delta 20), reused 57 (delta 13), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (79/79), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JzaI455s--N",
        "colab_type": "code",
        "outputId": "f18e9aa0-fb47-4008-d3f9-9a40c1702f39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import glob\n",
        "\n",
        "def read_data(directory):\n",
        "  file_paths = glob.glob(directory +\"*.txt\")    \n",
        "  text = \"\"\n",
        "  for file_path in file_paths:\n",
        "    with open(file_path, 'r', encoding=\"utf-8-sig\") as file:\n",
        "      file_content = file.read()\n",
        "      text+=file_content\n",
        "  return text\n",
        "\n",
        "directory1 = \"books-data/kafka/\"\n",
        "directory2 = \"books-data/shelley/\"\n",
        "directory3 = \"books-data/defoe/\"\n",
        "directory4 = \"books-data/plato/\"\n",
        "\n",
        "text = read_data(directory1)\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 571642 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx7Gn9OstLgt",
        "colab_type": "code",
        "outputId": "8da9d583-e702-4278-c42d-c9e775e9491f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import string\n",
        "\n",
        "class DataProcessor:\n",
        "\tdef __init__(self, chars_to_remove, chars_to_translate, replacement_chars):\n",
        "\t\tself.chars_to_remove = chars_to_remove\n",
        "\t\tself.chars_to_translate = chars_to_translate\n",
        "\t\tself.replacement_chars = replacement_chars\n",
        "\n",
        "\tdef preprocess_data(self, text):\n",
        "\t\tremoval_translator = str.maketrans(\"\", \"\", self.chars_to_remove)\n",
        "\t\tspecial_characters_translator = str.maketrans(self.chars_to_translate, self.replacement_chars , '')\n",
        "\t\ttext = text.lower().translate(removal_translator).translate(special_characters_translator)\n",
        "\t\ttext = \"\".join( list( map(DataProcessor.__split_punctuation_from_sentence , text)))\n",
        "\t\ttext = \" \".join(text.split())\n",
        "\t\treturn text\n",
        "\t\n",
        "\t@staticmethod\n",
        "\tdef __split_punctuation_from_sentence(char):\n",
        "\t\tif (char == '.' or char == ','):\n",
        "\t\t  return (\" \" + char + \" \")\n",
        "\t\telse:\n",
        "\t\t\treturn (char)\n",
        "\n",
        "characters_to_remove = '–—”„…«»‘’“°ſ†•✠' + '!\\\"#$%&\\'()*+-/:;<=>?@[\\]^_`{|}~' + string.digits  \n",
        "characters_to_translate = 'ąćęłńóśźżäöüæèêéôâáà£çëîñòùúûāœï'\n",
        "replacement_characters = 'acelnoszzaoueeeeoaaaeceinouuuaei'\n",
        "\n",
        "dataprocessor = DataProcessor(characters_to_remove, characters_to_translate, replacement_characters)\n",
        "text = dataprocessor.preprocess_data(text)\n",
        "\n",
        "unique_characters = sorted(list(set(text)))\n",
        "print ('{} unique characters:'.format(len(unique_characters)))\n",
        "print(unique_characters)\n",
        "\n",
        "words = text.split()\n",
        "print('Total words:', len(words))\n",
        "\n",
        "vocab = sorted(set(words))\n",
        "vocab_size = len(vocab)\n",
        "print('Unique words:', vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29 unique characters:\n",
            "[' ', ',', '.', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "Total words: 117176\n",
            "Unique words: 5611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1_JeAMxK6q0",
        "colab_type": "code",
        "outputId": "f01d35c1-325d-4949-e1ea-c0c5a6274d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from random import randint\n",
        "\n",
        "word_to_indices = dict((w, i) for i, w in enumerate(vocab))\n",
        "indices_to_word = dict((i, w) for i, w in enumerate(vocab))\n",
        "\n",
        "class Dataset:\n",
        "\tdef __init__(self):\n",
        "\t\tself.text_sequences = list()\n",
        "\t\tself.X_train = list()\n",
        "\t\tself.y_train = list()\n",
        "\t\tself.X_val = list()\n",
        "\t\tself.y_val = list()\n",
        "\n",
        "\tdef make_dataset(self, words, input_sequence_length=10, output_sequence_length=1):\n",
        "\t\tsequence_length = input_sequence_length + output_sequence_length \n",
        "\t\ttokens = self.__create_tokens(words, sequence_length)\n",
        "\t\tself.__create_training_and_validation_set(tokens)\n",
        "\t\treturn self\n",
        "\n",
        "\tdef __create_tokens(self, words, sequence_length):\n",
        "\t\tencoded_words = [word_to_indices[word] for word in words]\n",
        "\t\ttokens = list()\n",
        "\t\tfor i in range(sequence_length, len(words)):\n",
        "\t\t\tline = ' '.join(words[i-sequence_length:i])\n",
        "\t\t\tself.text_sequences.append(line)\n",
        "\t\t\ttokens.append(encoded_words[i-sequence_length:i])\n",
        "\t\treturn tokens\n",
        "\n",
        "\tdef __create_training_and_validation_set(self, tokens):\n",
        "\t\tdata = np.asarray(tokens)\n",
        "\t\tX, y = data[:,:-1], data[:,-1]\n",
        "\t\ty = np_utils.to_categorical(y, num_classes=vocab_size)\n",
        "\t\tself.X_train, self.X_val, self.y_train, self.y_val = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "\tdef get_random_sequence(self):\n",
        "\t\treturn self.text_sequences[randint(0, len(self.text_sequences))]\n",
        "    \n",
        "input_sequence_length = 10\n",
        "output_sequence_length = 1\n",
        "dataset = Dataset().make_dataset(words, input_sequence_length, output_sequence_length)\n",
        "\n",
        "print('Total Sequences:',  len(dataset.text_sequences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total Sequences: 117165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rJdBfKfHAvR",
        "colab_type": "code",
        "outputId": "45fa667c-7aa8-4489-b839-006f63451a32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization, Embedding\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "\n",
        "class Model:\n",
        "  def __init__(self):\n",
        "    self.model = Sequential()\n",
        "    self.__build_model()\n",
        "    self.__compile_model()\n",
        "    self.model.summary()\n",
        "\n",
        "  def __build_model(self):\n",
        "    self.model.add(Embedding(vocab_size, 50, input_length=input_sequence_length))\n",
        "    self.model.add(LSTM(100, return_sequences=True, recurrent_initializer='glorot_uniform', kernel_constraint=max_norm(3)))\n",
        "    self.model.add(BatchNormalization())\n",
        "    self.model.add(LSTM(100, recurrent_initializer='glorot_uniform', kernel_constraint=max_norm(3)))\n",
        "    self.model.add(BatchNormalization())\n",
        "    self.model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "  def __compile_model(self):\n",
        "    self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  def fit_model(self, X_train, y_train, validation_data, epochs, batch_size, callbacks):\n",
        "    return self.model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        validation_data=validation_data,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        verbose=2,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 10, 50)            280550    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 10, 100)           60400     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 10, 100)           400       \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5611)              566711    \n",
            "=================================================================\n",
            "Total params: 988,861\n",
            "Trainable params: 988,461\n",
            "Non-trainable params: 400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEjs3RAWosq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def generate_text(model, seed, words_amount):\n",
        "\tresult = list()\n",
        "\tinput_text = seed\n",
        "\tfor _ in range(words_amount):\n",
        "\t\tencoded_text = [word_to_indices[word] for word in input_text.split()]\n",
        "\t\tencoded_text = pad_sequences([encoded_text], maxlen=input_sequence_length, truncating='pre')\n",
        "\t\tpredictions = model.predict_classes(encoded_text, verbose=0)\n",
        "\t\tpredicted_word = indices_to_word[predictions[0]]\n",
        "\t\tinput_text += ' ' + predicted_word\n",
        "\t\tresult.append(predicted_word)\n",
        "\tresult = ' '.join(result).replace(\" ,\", \",\").replace(\" .\", \".\\n\")\n",
        "\treturn result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vDwadZxl_RE",
        "colab_type": "code",
        "outputId": "aad185c7-5705-4b1d-890c-1a1adfb8e41c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping as EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LambdaCallback, Callback\n",
        "\n",
        "seed_for_epochs = dataset.get_random_sequence()\n",
        "print(\"Checking with seed:\", seed_for_epochs)\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    print()\n",
        "    print('Generated text:')\n",
        "    print(generate_text(model.model, seed=seed_for_epochs, words_amount=50))\n",
        "    print()\n",
        "    \n",
        "text_generation = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking with seed: all of a sudden , they start developing a long time\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqTJJpNdgxAN",
        "colab_type": "code",
        "outputId": "14e6008a-87fe-4c36-ace6-ef639fbdab23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 100\n",
        "callbacks = [early_stopping, text_generation]\n",
        "history = model.fit_model(dataset.X_train, dataset.y_train, validation_data=(dataset.X_val, dataset.y_val), epochs=epochs, batch_size=batch_size, callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 93732 samples, validate on 23433 samples\n",
            "Epoch 1/5\n",
            "\n",
            "Generated text:\n",
            ". i can do you, said k, said k, said k, said k, said k, said k, said k, said k, said k, said k, said k, said k, said k, said k, said k\n",
            "\n",
            "93732/93732 - 25s - loss: 5.9423 - accuracy: 0.1155 - val_loss: 5.2601 - val_accuracy: 0.1348\n",
            "Epoch 2/5\n",
            "\n",
            "Generated text:\n",
            ", and the painter was not to be able to see him.\n",
            " he was not to be able to go to the door.\n",
            " and then, he looked at the door, and the deputy director was not to be able to see him.\n",
            " he was not\n",
            "\n",
            "93732/93732 - 15s - loss: 4.7296 - accuracy: 0.1744 - val_loss: 4.9404 - val_accuracy: 0.1599\n",
            "Epoch 3/5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvGYym0ErunF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make characteristics\n",
        "training_loss = history.history['loss']\n",
        "validation_loss = history.history['val_loss']\n",
        "training_acc = history.history['accuracy']\n",
        "validation_acc = history.history['val_accuracy']\n",
        "\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "f = plt.figure(figsize=(14,6))\n",
        "\n",
        "a0 = f.add_subplot(121)\n",
        "a0.plot(epoch_count, training_loss, 'r--', label=\"Training loss\")\n",
        "a0.plot(epoch_count, validation_loss, 'b-', label=\"Validation loss\")\n",
        "a0.legend()\n",
        "a0.set_title(\"Loss function\")\n",
        "a0.set_xlabel(\"Epoch\")\n",
        "plt.xlim(0, epochs)\n",
        "a0.set_ylabel(\"Loss\")\n",
        "plt.ylim(0, np.ceil(max(training_loss)))\n",
        "\n",
        "a1 = f.add_subplot(122)\n",
        "a1.plot(epoch_count, training_acc, 'r--', label=\"Training acc\")\n",
        "a1.plot(epoch_count, validation_acc, 'b-', label=\"Validation acc\")\n",
        "a1.set_title(\"Accuracy function\")\n",
        "a1.set_xlabel(\"Epoch\")\n",
        "plt.xlim(0, epochs)\n",
        "a1.set_ylabel(\"Acc\")\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeYovz3qofnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = dataset.get_random_sequence()\n",
        "print(\"Generating with seed:\",seed, \"\\n\")\n",
        "generated_text = generate_text(model.model, seed, words_amount=50)\n",
        "print(generated_text)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}